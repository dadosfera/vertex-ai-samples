{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60b1b3e-cd98-4fe6-88b8-824d80d5dae2",
   "metadata": {},
   "source": [
    "## Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c3ebd96-acab-4e62-b06c-a3a0f2388458",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jchavezar-demo'\n",
    "TRAIN_IMAGE = 'gcr.io/jchavezar-demo/pytorch-custom-random-t:v2'\n",
    "PREDICTION_IMAGE = 'gcr.io/jchavezar-demo/pytorch-custom-random-p:v2'\n",
    "STAGING_BUCKET = 'gs://vtx-staging'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e977185f-b448-430d-81f7-9b2080fad23d",
   "metadata": {},
   "source": [
    "# Training Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "753aca93-d2c7-4685-8838-450eb47996be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Folder Code Files Structure\n",
    "!rm -fr training\n",
    "!mkdir training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c63d31b-0652-4249-a479-cd1819564bd8",
   "metadata": {},
   "source": [
    "## Create Training Code [PyTorch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b957a97-1a02-4635-a2e5-20c2e77d6677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing source/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training/train.py\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def make_mixed_classification(n_samples, n_features, n_categories):\n",
    "    X,y = make_classification(n_samples=n_samples, n_features=n_features, random_state=42, n_informative=5)\n",
    "    cat_cols = random.choices(list(range(X.shape[-1])),k=n_categories)\n",
    "    num_cols = [i for i in range(X.shape[-1]) if i not in cat_cols]\n",
    "    for col in cat_cols:\n",
    "        X[:,col] = pd.qcut(X[:,col], q=4).codes.astype(int)\n",
    "    col_names = [] \n",
    "    num_col_names=[]\n",
    "    cat_col_names=[]\n",
    "    for i in range(X.shape[-1]):\n",
    "        if i in cat_cols:\n",
    "            col_names.append(f\"cat_col_{i}\")\n",
    "            cat_col_names.append(f\"cat_col_{i}\")\n",
    "        if i in num_cols:\n",
    "            col_names.append(f\"num_col_{i}\")\n",
    "            num_col_names.append(f\"num_col_{i}\")\n",
    "    X = pd.DataFrame(X, columns=col_names)\n",
    "    y = pd.Series(y, name=\"target\")\n",
    "    data = X.join(y)\n",
    "    return data, cat_col_names, num_col_names\n",
    "\n",
    "def print_metrics(y_true, y_pred, tag):\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\n",
    "        y_pred = y_pred.values\n",
    "    if y_true.ndim>1:\n",
    "        y_true=y_true.ravel()\n",
    "    if y_pred.ndim>1:\n",
    "        y_pred=y_pred.ravel()\n",
    "    val_acc = accuracy_score(y_true, y_pred)\n",
    "    val_f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"{tag} Acc: {val_acc} | {tag} F1: {val_f1}\")\n",
    "\n",
    "\n",
    "data, cat_col_names, num_col_names = make_mixed_classification(n_samples=10000, n_features=20, n_categories=4)\n",
    "train, test = train_test_split(data, random_state=42)\n",
    "train, val = train_test_split(train, random_state=42)\n",
    "path = os.path.join('/gcs/vtx-datasets-public', 'synthetic_data')\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "test.to_csv(f'{path}/test.csv', index=False)\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    accelerator=\"auto\", # can be 'cpu','gpu', 'tpu', or 'ipu' \n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", # No additional layer in head, just a mapping layer to output_dim\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__ # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"32-16\", # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\", # Activation between each layers\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\",\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    "    learning_rate = 1e-3\n",
    ")\n",
    "\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=train, validation=val)\n",
    "tabular_model.save_model('/gcs/vtx-models/pytorch/tabular_random')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a8e4c-9aff-448f-9434-e46a4e477596",
   "metadata": {},
   "source": [
    "### Build Image and Push to GCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e83e13e-7f96-48c4-8b6a-2a7ec996dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing source/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile training/Dockerfile\n",
    "FROM pytorch/pytorch:1.12.1-cuda11.3-cudnn8-devel\n",
    "\n",
    "COPY . .\n",
    "RUN pip install pytorch_tabular[extra]\n",
    "\n",
    "ENTRYPOINT [\"python\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79287209-59e5-4fa5-86a9-bacb978c67fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud builds submit -t $TRAIN_IMAGE training/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba4303-b781-426d-9552-9b8f4c96f954",
   "metadata": {},
   "source": [
    "## Run Training CustomJob using Container Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a952de4f-62d4-43c3-b9d5-5c55340ed01f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/569083142710/locations/us-central1/customJobs/376802222521974784\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/569083142710/locations/us-central1/customJobs/376802222521974784')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/376802222521974784?project=569083142710\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/376802222521974784 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "CustomJob run completed. Resource name: projects/569083142710/locations/us-central1/customJobs/376802222521974784\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=STAGING_BUCKET)\n",
    "\n",
    "worker_pool_specs = [\n",
    "        {\n",
    "            \"machine_spec\": {\n",
    "                \"machine_type\": \"n1-standard-4\",\n",
    "                \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "                \"accelerator_count\": 1,\n",
    "            },\n",
    "            \"replica_count\": 1,\n",
    "            \"container_spec\": {\n",
    "                \"image_uri\": TRAIN_IMAGE,\n",
    "                \"command\": [],\n",
    "                \"args\": [],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "my_job = aiplatform.CustomJob(\n",
    "    display_name='pytorch_tabular_custom',\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    ")\n",
    "\n",
    "my_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c00c138-d1bc-4ac8-a9d3-80a25195e834",
   "metadata": {},
   "source": [
    "# Prediction Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3bc350a3-c5d9-4fb0-9322-2235f51f9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Folder Code Files Structure\n",
    "!rm -fr prediction\n",
    "!mkdir prediction\n",
    "!mkdir prediction/app\n",
    "!mkdir prediction/app/tabular_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca8f0c-534e-4868-bd90-6d9ca2b156c3",
   "metadata": {},
   "source": [
    "## Create Prediction Code [Uvicorn:FastAPI PyTorch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b9cbf60-7663-446b-8c57-6f736ac40646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prediction/app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prediction/app/main.py\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from fastapi import Request, FastAPI\n",
    "from pytorch_tabular import TabularModel\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "loaded_model = TabularModel.load_from_checkpoint(\"tabular_random\")\n",
    "\n",
    "@app.get('/health_check')\n",
    "def health():\n",
    "    return 200\n",
    "if os.environ.get('AIP_PREDICT_ROUTE') is not None:\n",
    "    method = os.environ['AIP_PREDICT_ROUTE']\n",
    "else:\n",
    "    method = '/predict'\n",
    "\n",
    "@app.post(method)\n",
    "async def predict(request: Request):\n",
    "    print(\"----------------- PREDICTING -----------------\")\n",
    "    body = await request.json()\n",
    "    instances = body[\"instances\"]\n",
    "    columns = ['num_col_0','cat_col_1','num_col_2','num_col_3','cat_col_4',\n",
    "    'num_col_5','cat_col_6','num_col_7','num_col_8','cat_col_9','num_col_10',\n",
    "    'num_col_11','num_col_12','num_col_13','num_col_14','num_col_15','num_col_16',\n",
    "    'num_col_17','num_col_18','num_col_19']\n",
    "\n",
    "    data_pred = pd.DataFrame([instances],columns=columns)\n",
    "    outputs = loaded_model.predict(data_pred)\n",
    "    response = outputs['prediction'].tolist()\n",
    "    print(\"----------------- OUTPUTS -----------------\")\n",
    "    return {\"predictions\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477fabc-b57d-4d75-b5cb-475a79595bf6",
   "metadata": {},
   "source": [
    "### Build Image and Push to GCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd46aa1c-eafb-45e8-8d97-7fc00e1a82b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prediction/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile prediction/Dockerfile\n",
    "FROM pytorch/pytorch:1.12.1-cuda11.3-cudnn8-devel\n",
    "\n",
    "COPY app /app\n",
    "WORKDIR /app\n",
    "\n",
    "RUN pip install pytorch_tabular[extra]\n",
    "RUN pip install uvicorn fastapi\n",
    "\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af7b36-2658-4dea-b037-c6ae4e182cf4",
   "metadata": {},
   "source": [
    "## Copy Model from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04090b1c-6318-4b15-a6ec-ec09ced9e509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://vtx-models/pytorch/tabular_random/callbacks.sav...\n",
      "Copying gs://vtx-models/pytorch/tabular_random/config.yml...                    \n",
      "Copying gs://vtx-models/pytorch/tabular_random/custom_params.sav...             \n",
      "Copying gs://vtx-models/pytorch/tabular_random/datamodule.sav...                \n",
      "/ [4 files][  2.2 MiB/  2.2 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://vtx-models/pytorch/tabular_random/model.ckpt...\n",
      "/ [5 files][  2.2 MiB/  2.2 MiB]                                                \n",
      "Operation completed over 5 objects/2.2 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://vtx-models/pytorch/tabular_random/*.* prediction/app/tabular_random/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb615d-29a5-4d80-9160-1383a6cc9796",
   "metadata": {},
   "source": [
    "## Create Container Image and Push it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29dab6a1-22db-4856-aedd-ecd60b37f98c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 7 file(s) totalling 2.2 MiB before compression.\n",
      "Uploading tarball of [prediction/.] to [gs://jchavezar-demo_cloudbuild/source/1679369929.449695-72898d9129914afaaa3c9fc037f16c5f.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jchavezar-demo/locations/global/builds/1e68b91c-142e-4d86-bcca-39fc37fc49e1].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/1e68b91c-142e-4d86-bcca-39fc37fc49e1?project=569083142710 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"1e68b91c-142e-4d86-bcca-39fc37fc49e1\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jchavezar-demo_cloudbuild/source/1679369929.449695-72898d9129914afaaa3c9fc037f16c5f.tgz#1679369930444749\n",
      "Copying gs://jchavezar-demo_cloudbuild/source/1679369929.449695-72898d9129914afaaa3c9fc037f16c5f.tgz#1679369930444749...\n",
      "/ [1 files][  1.4 MiB/  1.4 MiB]                                                \n",
      "Operation completed over 1 objects/1.4 MiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  2.319MB\n",
      "Step 1/6 : FROM pytorch/pytorch:1.12.1-cuda11.3-cudnn8-devel\n",
      "1.12.1-cuda11.3-cudnn8-devel: Pulling from pytorch/pytorch\n",
      "40dd5be53814: Pulling fs layer\n",
      "0645c48e225b: Pulling fs layer\n",
      "8889d023c18e: Pulling fs layer\n",
      "74115353f57d: Pulling fs layer\n",
      "9e0ea72fe76c: Pulling fs layer\n",
      "13f51f3f80fd: Pulling fs layer\n",
      "c4ba9103d17d: Pulling fs layer\n",
      "8d9b8d71f868: Pulling fs layer\n",
      "97badaa6a776: Pulling fs layer\n",
      "63041bc7286a: Pulling fs layer\n",
      "5f237510596a: Pulling fs layer\n",
      "e84ba40a3ba2: Pulling fs layer\n",
      "3514d699b3b1: Pulling fs layer\n",
      "74115353f57d: Waiting\n",
      "9e0ea72fe76c: Waiting\n",
      "13f51f3f80fd: Waiting\n",
      "c4ba9103d17d: Waiting\n",
      "8d9b8d71f868: Waiting\n",
      "97badaa6a776: Waiting\n",
      "63041bc7286a: Waiting\n",
      "e84ba40a3ba2: Waiting\n",
      "3514d699b3b1: Waiting\n",
      "0645c48e225b: Verifying Checksum\n",
      "0645c48e225b: Download complete\n",
      "8889d023c18e: Verifying Checksum\n",
      "8889d023c18e: Download complete\n",
      "40dd5be53814: Verifying Checksum\n",
      "40dd5be53814: Download complete\n",
      "74115353f57d: Verifying Checksum\n",
      "74115353f57d: Download complete\n",
      "9e0ea72fe76c: Verifying Checksum\n",
      "9e0ea72fe76c: Download complete\n",
      "c4ba9103d17d: Verifying Checksum\n",
      "c4ba9103d17d: Download complete\n",
      "97badaa6a776: Download complete\n",
      "40dd5be53814: Pull complete\n",
      "0645c48e225b: Pull complete\n",
      "8889d023c18e: Pull complete\n",
      "74115353f57d: Pull complete\n",
      "13f51f3f80fd: Verifying Checksum\n",
      "13f51f3f80fd: Download complete\n",
      "9e0ea72fe76c: Pull complete\n",
      "5f237510596a: Verifying Checksum\n",
      "5f237510596a: Download complete\n",
      "8d9b8d71f868: Verifying Checksum\n",
      "8d9b8d71f868: Download complete\n",
      "3514d699b3b1: Verifying Checksum\n",
      "3514d699b3b1: Download complete\n",
      "63041bc7286a: Download complete\n",
      "e84ba40a3ba2: Verifying Checksum\n",
      "e84ba40a3ba2: Download complete\n",
      "13f51f3f80fd: Pull complete\n",
      "c4ba9103d17d: Pull complete\n",
      "8d9b8d71f868: Pull complete\n",
      "97badaa6a776: Pull complete\n",
      "63041bc7286a: Pull complete\n",
      "5f237510596a: Pull complete\n",
      "e84ba40a3ba2: Pull complete\n",
      "3514d699b3b1: Pull complete\n",
      "Digest: sha256:dda4e7ce91e3f5b309233111b251e54cf47b44a742fe37c7f68d9429321fa0f9\n",
      "Status: Downloaded newer image for pytorch/pytorch:1.12.1-cuda11.3-cudnn8-devel\n",
      " ---> fa50f7fed43a\n",
      "Step 2/6 : COPY app /app\n",
      " ---> fc7b3bcd3deb\n",
      "Step 3/6 : WORKDIR /app\n",
      " ---> Running in 2048fd0aaa88\n",
      "Removing intermediate container 2048fd0aaa88\n",
      " ---> 4a6b203345ba\n",
      "Step 4/6 : RUN pip install pytorch_tabular[extra]\n",
      " ---> Running in b076f7a9767a\n",
      "Collecting pytorch_tabular[extra]\n",
      "  Downloading pytorch_tabular-1.0.1-py2.py3-none-any.whl (119 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.7/119.7 kB 6.8 MB/s eta 0:00:00\n",
      "Collecting pytorch-lightning==1.8.*\n",
      "  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 800.3/800.3 kB 26.6 MB/s eta 0:00:00\n",
      "Collecting PyYAML<=5.4.1,>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 636.6/636.6 kB 42.1 MB/s eta 0:00:00\n",
      "Collecting pytorch-tabnet==4.0\n",
      "  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.8/41.8 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard!=2.5.0,>=2.2.0\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 42.9 MB/s eta 0:00:00\n",
      "Collecting omegaconf>=2.0.1\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 10.8 MB/s eta 0:00:00\n",
      "Collecting protobuf<=3.20.*\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 53.7 MB/s eta 0:00:00\n",
      "Collecting rich>=10.2.2\n",
      "  Downloading rich-13.3.2-py3-none-any.whl (238 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 238.7/238.7 kB 27.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_tabular[extra]) (1.12.1)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.8/137.8 kB 14.9 MB/s eta 0:00:00\n",
      "Collecting torchmetrics==0.11.*\n",
      "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 519.2/519.2 kB 38.4 MB/s eta 0:00:00\n",
      "Collecting scikit-learn>=1.0.0\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.8/24.8 MB 27.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch_tabular[extra]) (1.21.5)\n",
      "Collecting einops==0.6.*\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.6/41.6 kB 5.6 MB/s eta 0:00:00\n",
      "Collecting category-encoders==2.5.*\n",
      "  Downloading category_encoders-2.5.1.post0-py2.py3-none-any.whl (72 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.4/72.4 kB 9.5 MB/s eta 0:00:00\n",
      "Collecting matplotlib>3.1\n",
      "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 39.2 MB/s eta 0:00:00\n",
      "Collecting pandas>=1.1.5\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.3/11.3 MB 33.6 MB/s eta 0:00:00\n",
      "Collecting kaleido==0.2.*\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.9/79.9 MB 6.1 MB/s eta 0:00:00\n",
      "Collecting plotly==4.14.*\n",
      "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.2/13.2 MB 42.7 MB/s eta 0:00:00\n",
      "Collecting wandb==0.13.*\n",
      "  Downloading wandb-0.13.11-py3-none-any.whl (2.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 66.3 MB/s eta 0:00:00\n",
      "Collecting statsmodels>=0.9.0\n",
      "  Downloading statsmodels-0.13.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 50.1 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.0.0\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.1/38.1 MB 22.0 MB/s eta 0:00:00\n",
      "Collecting patsy>=0.5.1\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.8/233.8 kB 25.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from plotly==4.14.*->pytorch_tabular[extra]) (1.16.0)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.8.*->pytorch_tabular[extra]) (4.3.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.8.*->pytorch_tabular[extra]) (4.63.0)\n",
      "Collecting fsspec[http]>2021.06.0\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.0/143.0 kB 18.3 MB/s eta 0:00:00\n",
      "Collecting packaging>=17.0\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.7/42.7 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting lightning-utilities!=0.4.0,>=0.3.0\n",
      "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting tensorboardX>=2.2\n",
      "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 14.5 MB/s eta 0:00:00\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.17.0-py2.py3-none-any.whl (189 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 189.1/189.1 kB 20.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb==0.13.*->pytorch_tabular[extra]) (61.2.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.13.*->pytorch_tabular[extra]) (5.8.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting Click!=8.0.0,>=7.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 kB 13.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.13.*->pytorch_tabular[extra]) (2.27.1)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 23.7 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 8.7 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 965.4/965.4 kB 53.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (9.0.1)\n",
      "Collecting python-dateutil>=2.7\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 28.5 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 kB 15.1 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 17.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.5->pytorch_tabular[extra]) (2022.1)\n",
      "Collecting markdown-it-py<3.0.0,>=2.2.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.5/84.5 kB 11.2 MB/s eta 0:00:00\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 55.0 MB/s eta 0:00:00\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 kB 31.2 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.2/177.2 kB 21.0 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 10.6 MB/s eta 0:00:00\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 22.7 MB/s eta 0:00:00\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 18.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular[extra]) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 53.6 MB/s eta 0:00:00\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 49.4 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.6/233.6 kB 27.4 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting ipykernel>=4.5.1\n",
      "  Downloading ipykernel-6.16.2-py3-none-any.whl (138 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.5/138.5 kB 19.0 MB/s eta 0:00:00\n",
      "Collecting jupyterlab-widgets~=3.0\n",
      "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 384.3/384.3 kB 37.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pytorch_tabular[extra]) (7.31.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->pytorch_tabular[extra]) (5.1.1)\n",
      "Collecting widgetsnbextension~=4.0\n",
      "  Downloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 72.6 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-6.1.0-py3-none-any.whl (21 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (948 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 948.1/948.1 kB 63.7 MB/s eta 0:00:00\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 9.8 MB/s eta 0:00:00\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 21.9 MB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting debugpy>=1.0\n",
      "  Downloading debugpy-1.6.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 78.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular[extra]) (0.1.2)\n",
      "Collecting tornado>=6.1\n",
      "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 424.0/424.0 kB 39.6 MB/s eta 0:00:00\n",
      "Collecting nest-asyncio\n",
      "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
      "Collecting jupyter-client>=6.1.12\n",
      "  Downloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.5/133.5 kB 19.4 MB/s eta 0:00:00\n",
      "Collecting pyzmq>=17\n",
      "  Downloading pyzmq-25.0.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 58.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (3.0.20)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.18.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb==0.13.*->pytorch_tabular[extra]) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb==0.13.*->pytorch_tabular[extra]) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb==0.13.*->pytorch_tabular[extra]) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb==0.13.*->pytorch_tabular[extra]) (2.0.4)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.9/140.9 kB 19.9 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 231.4/231.4 kB 23.9 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 148.0/148.0 kB 20.2 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.8/94.8 kB 12.6 MB/s eta 0:00:00\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.0/60.0 kB 7.9 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.8.3)\n",
      "Collecting jupyter-core>=4.9.2\n",
      "  Downloading jupyter_core-4.12.0-py3-none-any.whl (89 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.9/89.9 kB 12.7 MB/s eta 0:00:00\n",
      "Collecting entrypoints\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.2.5)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 555.4 kB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 21.2 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: antlr4-python3-runtime, pathtools\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=99674524bff3f65d58c4ce9bac73d76ecc9c329f5d9b97c02eaa24358f7a76fb\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=88fd9110fb7609d35f3e26ca91f5c1698a4ae848f8bc944c83ded8984fafe756\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "Successfully built antlr4-python3-runtime pathtools\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, pathtools, kaleido, appdirs, antlr4-python3-runtime, zipp, widgetsnbextension, urllib3, tornado, threadpoolctl, tensorboard-data-server, smmap, setproctitle, scipy, rsa, retrying, pyzmq, PyYAML, python-dateutil, pyparsing, pygments, pyasn1-modules, protobuf, patsy, packaging, oauthlib, nest-asyncio, multidict, mdurl, MarkupSafe, kiwisolver, jupyterlab-widgets, jupyter-core, joblib, grpcio, fsspec, frozenlist, fonttools, entrypoints, einops, docker-pycreds, debugpy, cycler, cachetools, attrs, asynctest, async-timeout, absl-py, yarl, werkzeug, torchmetrics, tensorboardX, sentry-sdk, scikit-learn, plotly, pandas, omegaconf, matplotlib, markdown-it-py, jupyter-client, importlib-metadata, google-auth, gitdb, aiosignal, statsmodels, rich, requests-oauthlib, pytorch-tabnet, markdown, lightning-utilities, ipykernel, GitPython, Click, aiohttp, wandb, ipywidgets, google-auth-oauthlib, category-encoders, tensorboard, pytorch-lightning, pytorch_tabular\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.8\n",
      "    Uninstalling urllib3-1.26.8:\n",
      "      Successfully uninstalled urllib3-1.26.8\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Uninstalling MarkupSafe-2.0.1:\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\n",
      "Successfully installed Click-8.1.3 GitPython-3.1.31 MarkupSafe-2.1.2 PyYAML-5.4.1 absl-py-1.4.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 async-timeout-4.0.2 asynctest-0.13.0 attrs-22.2.0 cachetools-5.3.0 category-encoders-2.5.1.post0 cycler-0.11.0 debugpy-1.6.6 docker-pycreds-0.4.0 einops-0.6.0 entrypoints-0.4 fonttools-4.38.0 frozenlist-1.3.3 fsspec-2023.1.0 gitdb-4.0.10 google-auth-2.16.2 google-auth-oauthlib-0.4.6 grpcio-1.51.3 importlib-metadata-6.1.0 ipykernel-6.16.2 ipywidgets-8.0.4 joblib-1.2.0 jupyter-client-7.4.9 jupyter-core-4.12.0 jupyterlab-widgets-3.0.5 kaleido-0.2.1 kiwisolver-1.4.4 lightning-utilities-0.8.0 markdown-3.4.1 markdown-it-py-2.2.0 matplotlib-3.5.3 mdurl-0.1.2 multidict-6.0.4 nest-asyncio-1.5.6 oauthlib-3.2.2 omegaconf-2.3.0 packaging-23.0 pandas-1.3.5 pathtools-0.1.2 patsy-0.5.3 plotly-4.14.3 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 pygments-2.14.0 pyparsing-3.0.9 python-dateutil-2.8.2 pytorch-lightning-1.8.6 pytorch-tabnet-4.0 pytorch_tabular-1.0.1 pyzmq-25.0.2 requests-oauthlib-1.3.1 retrying-1.3.4 rich-13.3.2 rsa-4.9 scikit-learn-1.0.2 scipy-1.7.3 sentry-sdk-1.17.0 setproctitle-1.3.2 smmap-5.0.0 statsmodels-0.13.5 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorboardX-2.6 threadpoolctl-3.1.0 torchmetrics-0.11.4 tornado-6.2 urllib3-1.26.15 wandb-0.13.11 werkzeug-2.2.3 widgetsnbextension-4.0.5 yarl-1.8.2 zipp-3.15.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container b076f7a9767a\n",
      " ---> ead23d6f2405\n",
      "Step 5/6 : RUN pip install uvicorn fastapi\n",
      " ---> Running in 3003e37694fb\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.8/57.8 kB 5.5 MB/s eta 0:00:00\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.1/57.1 kB 7.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from uvicorn) (8.1.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from uvicorn) (4.3.0)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 6.7 MB/s eta 0:00:00\n",
      "Collecting starlette<0.27.0,>=0.26.1\n",
      "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.9/66.9 kB 10.0 MB/s eta 0:00:00\n",
      "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
      "  Downloading pydantic-1.10.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 53.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=7.0->uvicorn) (6.1.0)\n",
      "Collecting anyio<5,>=3.4.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.6/80.6 kB 11.1 MB/s eta 0:00:00\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=7.0->uvicorn) (3.15.0)\n",
      "Installing collected packages: sniffio, pydantic, h11, anyio, uvicorn, starlette, fastapi\n",
      "Successfully installed anyio-3.6.2 fastapi-0.95.0 h11-0.14.0 pydantic-1.10.6 sniffio-1.3.0 starlette-0.26.1 uvicorn-0.21.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 3003e37694fb\n",
      " ---> 9532df9f7d10\n",
      "Step 6/6 : CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
      " ---> Running in 3bacccc79cf0\n",
      "Removing intermediate container 3bacccc79cf0\n",
      " ---> c39d40f5bab0\n",
      "Successfully built c39d40f5bab0\n",
      "Successfully tagged gcr.io/jchavezar-demo/pytorch-custom-random-p:v2\n",
      "PUSH\n",
      "Pushing gcr.io/jchavezar-demo/pytorch-custom-random-p:v2\n",
      "The push refers to repository [gcr.io/jchavezar-demo/pytorch-custom-random-p]\n",
      "7b79e9495b5d: Preparing\n",
      "972f833edab0: Preparing\n",
      "ac6ce0340399: Preparing\n",
      "15f183e4a151: Preparing\n",
      "fb6b2e2eb411: Preparing\n",
      "5e1186aeedd8: Preparing\n",
      "0041885325f3: Preparing\n",
      "f97d7bfa2470: Preparing\n",
      "b71fe7c57681: Preparing\n",
      "0928b408c376: Preparing\n",
      "bc6138ff1a00: Preparing\n",
      "e69dd799d565: Preparing\n",
      "14e004b831a9: Preparing\n",
      "462a153a48d3: Preparing\n",
      "17cf14264373: Preparing\n",
      "3e549931e024: Preparing\n",
      "5e1186aeedd8: Waiting\n",
      "0041885325f3: Waiting\n",
      "f97d7bfa2470: Waiting\n",
      "b71fe7c57681: Waiting\n",
      "0928b408c376: Waiting\n",
      "bc6138ff1a00: Waiting\n",
      "e69dd799d565: Waiting\n",
      "14e004b831a9: Waiting\n",
      "462a153a48d3: Waiting\n",
      "17cf14264373: Waiting\n",
      "3e549931e024: Waiting\n",
      "fb6b2e2eb411: Layer already exists\n",
      "15f183e4a151: Layer already exists\n",
      "0041885325f3: Layer already exists\n",
      "5e1186aeedd8: Layer already exists\n",
      "b71fe7c57681: Layer already exists\n",
      "f97d7bfa2470: Layer already exists\n",
      "0928b408c376: Layer already exists\n",
      "e69dd799d565: Layer already exists\n",
      "bc6138ff1a00: Layer already exists\n",
      "14e004b831a9: Layer already exists\n",
      "ac6ce0340399: Pushed\n",
      "462a153a48d3: Layer already exists\n",
      "17cf14264373: Layer already exists\n",
      "3e549931e024: Layer already exists\n",
      "7b79e9495b5d: Pushed\n",
      "972f833edab0: Pushed\n",
      "v2: digest: sha256:68f92caf324c5e06b69577cade3285b5adbb960acc741d4698e5753a1d5dae85 size: 3694\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                        IMAGES                                            STATUS\n",
      "1e68b91c-142e-4d86-bcca-39fc37fc49e1  2023-03-21T03:38:50+00:00  11M33S    gs://jchavezar-demo_cloudbuild/source/1679369929.449695-72898d9129914afaaa3c9fc037f16c5f.tgz  gcr.io/jchavezar-demo/pytorch-custom-random-p:v2  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit -t $PREDICTION_IMAGE prediction/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb93be-230d-4ae9-b9a7-8d2bb2462fe5",
   "metadata": {},
   "source": [
    "## Upload to Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71f9e3-16bf-44e0-9391-649d1af8ee92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/569083142710/locations/us-central1/models/7943630662076989440/operations/6286877539092660224\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=\"synthetic_data_pytorch\",\n",
    "    serving_container_image_uri=PREDICTION_IMAGE,\n",
    "    serving_container_health_route=\"/health_check\",\n",
    "    serving_container_ports=[8080]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e64392ec-9d4c-4c7a-ae5e-53050443ae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/569083142710/locations/us-central1/endpoints/9078777461709209600/operations/6746244701084450816\n",
      "Endpoint created. Resource name: projects/569083142710/locations/us-central1/endpoints/9078777461709209600\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/569083142710/locations/us-central1/endpoints/9078777461709209600')\n",
      "Deploying model to Endpoint : projects/569083142710/locations/us-central1/endpoints/9078777461709209600\n",
      "Deploy Endpoint model backing LRO: projects/569083142710/locations/us-central1/endpoints/9078777461709209600/operations/6575107915244371968\n",
      "Endpoint model deployed. Resource name: projects/569083142710/locations/us-central1/endpoints/9078777461709209600\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name='synthetic_data_pytorch',\n",
    "    machine_type='a2-highgpu-1g',\n",
    "    accelerator_type='NVIDIA_TESLA_A100',\n",
    "    accelerator_count=1,\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe683c-3b87-40aa-8c11-685db3794adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
