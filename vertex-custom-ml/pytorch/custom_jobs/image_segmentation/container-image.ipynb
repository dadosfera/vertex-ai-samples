{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jchavezar-demo' # @param {type:\"string\"}\n",
    "REGION = 'us-central1' # @param {type:\"string\"}\n",
    "MODEL_NAME = 'segformer-b0-finetuned-segments-sockcop-march-7'\n",
    "STAGING_URI = 'gs://vtx-staging/image_segmentation_road/gpu' # @param {type:\"string\"}\n",
    "TRAIN_IMAGE_URI = 'gcr.io/jchavezar-demo/pytorch-gpu:latest' # @param {type:\"string\"}\n",
    "#PREDICTION_IMAGE_URI = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest' # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../tkns')\n",
    "\n",
    "from sec import TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr source\n",
    "!mkdir source"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Image Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing source/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source/train.py\n",
    "#%%\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "import evaluate\n",
    "import multiprocessing\n",
    "import argparse\n",
    "from transformers import Trainer\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from torchvision.transforms import ColorJitter\n",
    "from transformers import (\n",
    "    SegformerFeatureExtractor,\n",
    ")\n",
    "from transformers import TrainingArguments\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--token', type=str,\n",
    "                    help='github token')\n",
    "parser.add_argument('--model_name', type=str,\n",
    "                    help='github model name')\n",
    "args = parser.parse_args()\n",
    "\n",
    "feature_extractor = SegformerFeatureExtractor()\n",
    "hf_username = \"segments-sockcop\"\n",
    "hf_dataset_identifier = \"segments/sidewalk-semantic\"\n",
    "pretrained_model_name = \"nvidia/mit-b0\"\n",
    "hub_model_id = args.model_name\n",
    "\n",
    "def extract_preprocess():\n",
    "    print('[INFO] ------ Data Extraction and Preprocess')\n",
    "    ds = load_dataset(hf_dataset_identifier)\n",
    "\n",
    "    ds = ds.shuffle(seed=1)\n",
    "    ds = ds[\"train\"].train_test_split(test_size=0.2)\n",
    "    train_ds = ds[\"train\"]\n",
    "    test_ds = ds[\"test\"]\n",
    "\n",
    "    filename = \"id2label.json\"\n",
    "    id2label = json.load(open(hf_hub_download(repo_id=hf_dataset_identifier, filename=filename, repo_type=\"dataset\"), \"r\"))\n",
    "    id2label = {int(k): v for k, v in id2label.items()}\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "    num_labels = len(id2label)\n",
    "    print(\"Id2label:\", id2label)\n",
    "\n",
    "    jitter = ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1) \n",
    "\n",
    "    def train_transforms(example_batch):\n",
    "        print('[INFO] ------ Training Transform Process')\n",
    "        images = [jitter(x) for x in example_batch['pixel_values']]\n",
    "        labels = [x for x in example_batch['label']]\n",
    "        inputs = feature_extractor(images, labels)\n",
    "        return inputs\n",
    "\n",
    "\n",
    "    def val_transforms(example_batch):\n",
    "        print('[INFO] ------ Validation Transform Process')\n",
    "        images = [x for x in example_batch['pixel_values']]\n",
    "        labels = [x for x in example_batch['label']]\n",
    "        inputs = feature_extractor(images, labels)\n",
    "        return inputs\n",
    "\n",
    "    train_ds.set_transform(train_transforms)\n",
    "    test_ds.set_transform(val_transforms)\n",
    "\n",
    "    # Set transforms\n",
    "    return train_ds, test_ds, id2label, label2id\n",
    "\n",
    "def trainer_build(train_ds, test_ds, id2label, label2id):\n",
    "    print('[INFO] ------ Training Build Process')\n",
    "    epochs = 50\n",
    "    lr = 0.00006\n",
    "    batch_size = 1 \n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "        pretrained_model_name,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        \"segformer-b0-finetuned-segments-sidewalk-outputs\",\n",
    "        learning_rate=lr,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        save_total_limit=3,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=20,\n",
    "        eval_steps=20,\n",
    "        logging_steps=1,\n",
    "        eval_accumulation_steps=5,\n",
    "        load_best_model_at_end=True,\n",
    "        push_to_hub=True,\n",
    "        hub_model_id=hub_model_id,\n",
    "        hub_strategy=\"end\",\n",
    "        hub_token=args.token\n",
    "    )\n",
    "\n",
    "    metric = evaluate.load(\"mean_iou\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        with torch.no_grad():\n",
    "            logits, labels = eval_pred\n",
    "            logits_tensor = torch.from_numpy(logits)\n",
    "            # scale the logits to the size of the label\n",
    "            logits_tensor = nn.functional.interpolate(\n",
    "                logits_tensor,\n",
    "                size=labels.shape[-2:],\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False,\n",
    "            ).argmax(dim=1)\n",
    "\n",
    "            pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "            metrics = metric._compute(\n",
    "                    predictions=pred_labels,\n",
    "                    references=labels,\n",
    "                    num_labels=len(id2label),\n",
    "                    ignore_index=0,\n",
    "                    reduce_labels=feature_extractor.reduce_labels,\n",
    "                )\n",
    "            \n",
    "            # add per category metrics as individual key-value pairs\n",
    "            per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
    "            per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
    "\n",
    "            metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
    "            metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
    "\n",
    "            return metrics\n",
    "\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    print(\"[INFO] ------ Pushing Model to HuggingHub\")\n",
    "    kwargs = {\n",
    "    \"tags\": [\"vision\", \"image-segmentation\"],\n",
    "    \"finetuned_from\": pretrained_model_name,\n",
    "    \"dataset\": hf_dataset_identifier,\n",
    "    }\n",
    "    feature_extractor.push_to_hub(hub_model_id)\n",
    "    trainer.push_to_hub(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_ds, test_ds, id2label, label2id = extract_preprocess()\n",
    "    print(train_ds)\n",
    "    trainer = trainer_build(train_ds, test_ds, id2label, label2id)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing source/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile source/Dockerfile\n",
    "\n",
    "FROM nvcr.io/nvidia/pytorch:21.02-py3\n",
    "\n",
    "COPY . .\n",
    "\n",
    "RUN curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "RUN apt-get update -y\n",
    "RUN apt-get install git-lfs\n",
    "RUN pip install jupyter ipykernel \n",
    "RUN pip install transformers datasets segments-ai evaluate git-lfs tqdm==4.59\n",
    "\n",
    "ENTRYPOINT [\"python\", \"train.py\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push To Google Cloud Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 2 file(s) totalling 5.4 KiB before compression.\n",
      "Uploading tarball of [source/.] to [gs://jchavezar-demo_cloudbuild/source/1678249191.947235-eea1ad046b4f4be48997bbcc0a24d369.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jchavezar-demo/locations/global/builds/c7b2845a-f93b-4a22-8be2-59fef2174550].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/c7b2845a-f93b-4a22-8be2-59fef2174550?project=569083142710 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"c7b2845a-f93b-4a22-8be2-59fef2174550\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jchavezar-demo_cloudbuild/source/1678249191.947235-eea1ad046b4f4be48997bbcc0a24d369.tgz#1678249193034842\n",
      "Copying gs://jchavezar-demo_cloudbuild/source/1678249191.947235-eea1ad046b4f4be48997bbcc0a24d369.tgz#1678249193034842...\n",
      "/ [1 files][  2.1 KiB/  2.1 KiB]                                                \n",
      "Operation completed over 1 objects/2.1 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  8.192kB\n",
      "Step 1/8 : FROM nvcr.io/nvidia/pytorch:21.02-py3\n",
      "21.02-py3: Pulling from nvidia/pytorch\n",
      "83ee3a23efb7: Pulling fs layer\n",
      "db98fc6f11f0: Pulling fs layer\n",
      "f611acd52c6c: Pulling fs layer\n",
      "28cab2098606: Pulling fs layer\n",
      "6b50c2484b47: Pulling fs layer\n",
      "b6d251b652e5: Pulling fs layer\n",
      "a81501e06699: Pulling fs layer\n",
      "d015e2eeb76c: Pulling fs layer\n",
      "4843fc0fc222: Pulling fs layer\n",
      "a62f4c9c11a5: Pulling fs layer\n",
      "d428983292c3: Pulling fs layer\n",
      "e6096bc2cdb2: Pulling fs layer\n",
      "d1cf1b4c9ff9: Pulling fs layer\n",
      "a61f0dbc7823: Pulling fs layer\n",
      "efb8675bd096: Pulling fs layer\n",
      "a89f774586d3: Pulling fs layer\n",
      "bf30963c88c4: Pulling fs layer\n",
      "c663aed72850: Pulling fs layer\n",
      "5bbce2800b70: Pulling fs layer\n",
      "da3cf001d3de: Pulling fs layer\n",
      "411fd9a22514: Pulling fs layer\n",
      "3e83295d72e4: Pulling fs layer\n",
      "4d0fb79fd071: Pulling fs layer\n",
      "40289936d166: Pulling fs layer\n",
      "e1d17392d33d: Pulling fs layer\n",
      "11d1c96ea8b8: Pulling fs layer\n",
      "eb9ca4875e99: Pulling fs layer\n",
      "92566ef21b5a: Pulling fs layer\n",
      "bc0b9f9e7350: Pulling fs layer\n",
      "38da30fc5f85: Pulling fs layer\n",
      "6b01a270cc2c: Pulling fs layer\n",
      "2f72dce5daac: Pulling fs layer\n",
      "4bf8fcfa2cf1: Pulling fs layer\n",
      "6b145641fd35: Pulling fs layer\n",
      "e7e5cf6583cf: Pulling fs layer\n",
      "79c93d08278e: Pulling fs layer\n",
      "ff8f3bf6fc5f: Pulling fs layer\n",
      "66b7878d2381: Pulling fs layer\n",
      "3875129dc0b4: Pulling fs layer\n",
      "936ae117a5bd: Pulling fs layer\n",
      "ca8201ec17dc: Pulling fs layer\n",
      "434d9209a8e2: Pulling fs layer\n",
      "739a441af6c5: Pulling fs layer\n",
      "0a6e73b9e158: Pulling fs layer\n",
      "f5180d7f71b0: Pulling fs layer\n",
      "04db425759c4: Pulling fs layer\n",
      "095fe49485f6: Pulling fs layer\n",
      "fb6cbf8649f8: Pulling fs layer\n",
      "53c8d7977378: Pulling fs layer\n",
      "cfecc077ebde: Pulling fs layer\n",
      "13167a35542b: Pulling fs layer\n",
      "67319511d846: Pulling fs layer\n",
      "da8a3441207d: Pulling fs layer\n",
      "482c01fefbdc: Pulling fs layer\n",
      "aa95744ff9f2: Pulling fs layer\n",
      "3a74d3c8b83b: Pulling fs layer\n",
      "6a5489f5c0b1: Pulling fs layer\n",
      "9e2bc2f0ba87: Pulling fs layer\n",
      "28cab2098606: Waiting\n",
      "6b50c2484b47: Waiting\n",
      "b6d251b652e5: Waiting\n",
      "a81501e06699: Waiting\n",
      "d015e2eeb76c: Waiting\n",
      "4843fc0fc222: Waiting\n",
      "a62f4c9c11a5: Waiting\n",
      "d428983292c3: Waiting\n",
      "e6096bc2cdb2: Waiting\n",
      "d1cf1b4c9ff9: Waiting\n",
      "a61f0dbc7823: Waiting\n",
      "efb8675bd096: Waiting\n",
      "a89f774586d3: Waiting\n",
      "bf30963c88c4: Waiting\n",
      "c663aed72850: Waiting\n",
      "5bbce2800b70: Waiting\n",
      "da3cf001d3de: Waiting\n",
      "411fd9a22514: Waiting\n",
      "3e83295d72e4: Waiting\n",
      "4d0fb79fd071: Waiting\n",
      "40289936d166: Waiting\n",
      "e1d17392d33d: Waiting\n",
      "11d1c96ea8b8: Waiting\n",
      "eb9ca4875e99: Waiting\n",
      "92566ef21b5a: Waiting\n",
      "bc0b9f9e7350: Waiting\n",
      "38da30fc5f85: Waiting\n",
      "6b01a270cc2c: Waiting\n",
      "2f72dce5daac: Waiting\n",
      "4bf8fcfa2cf1: Waiting\n",
      "6b145641fd35: Waiting\n",
      "e7e5cf6583cf: Waiting\n",
      "79c93d08278e: Waiting\n",
      "ff8f3bf6fc5f: Waiting\n",
      "66b7878d2381: Waiting\n",
      "3875129dc0b4: Waiting\n",
      "936ae117a5bd: Waiting\n",
      "ca8201ec17dc: Waiting\n",
      "434d9209a8e2: Waiting\n",
      "739a441af6c5: Waiting\n",
      "0a6e73b9e158: Waiting\n",
      "f5180d7f71b0: Waiting\n",
      "04db425759c4: Waiting\n",
      "095fe49485f6: Waiting\n",
      "fb6cbf8649f8: Waiting\n",
      "53c8d7977378: Waiting\n",
      "cfecc077ebde: Waiting\n",
      "13167a35542b: Waiting\n",
      "67319511d846: Waiting\n",
      "da8a3441207d: Waiting\n",
      "482c01fefbdc: Waiting\n",
      "aa95744ff9f2: Waiting\n",
      "3a74d3c8b83b: Waiting\n",
      "6a5489f5c0b1: Waiting\n",
      "9e2bc2f0ba87: Waiting\n",
      "f611acd52c6c: Verifying Checksum\n",
      "f611acd52c6c: Download complete\n",
      "db98fc6f11f0: Verifying Checksum\n",
      "db98fc6f11f0: Download complete\n",
      "83ee3a23efb7: Verifying Checksum\n",
      "83ee3a23efb7: Download complete\n",
      "b6d251b652e5: Verifying Checksum\n",
      "b6d251b652e5: Download complete\n",
      "a81501e06699: Verifying Checksum\n",
      "a81501e06699: Download complete\n",
      "d015e2eeb76c: Verifying Checksum\n",
      "d015e2eeb76c: Download complete\n",
      "28cab2098606: Verifying Checksum\n",
      "28cab2098606: Download complete\n",
      "4843fc0fc222: Verifying Checksum\n",
      "4843fc0fc222: Download complete\n",
      "a62f4c9c11a5: Verifying Checksum\n",
      "a62f4c9c11a5: Download complete\n",
      "83ee3a23efb7: Pull complete\n",
      "db98fc6f11f0: Pull complete\n",
      "d428983292c3: Verifying Checksum\n",
      "d428983292c3: Download complete\n",
      "f611acd52c6c: Pull complete\n",
      "e6096bc2cdb2: Verifying Checksum\n",
      "e6096bc2cdb2: Download complete\n",
      "6b50c2484b47: Verifying Checksum\n",
      "6b50c2484b47: Download complete\n",
      "d1cf1b4c9ff9: Verifying Checksum\n",
      "d1cf1b4c9ff9: Download complete\n",
      "efb8675bd096: Verifying Checksum\n",
      "efb8675bd096: Download complete\n",
      "a89f774586d3: Verifying Checksum\n",
      "a89f774586d3: Download complete\n",
      "bf30963c88c4: Verifying Checksum\n",
      "bf30963c88c4: Download complete\n",
      "c663aed72850: Verifying Checksum\n",
      "c663aed72850: Download complete\n",
      "da3cf001d3de: Verifying Checksum\n",
      "da3cf001d3de: Download complete\n",
      "411fd9a22514: Verifying Checksum\n",
      "411fd9a22514: Download complete\n",
      "5bbce2800b70: Verifying Checksum\n",
      "5bbce2800b70: Download complete\n",
      "4d0fb79fd071: Verifying Checksum\n",
      "4d0fb79fd071: Download complete\n",
      "3e83295d72e4: Verifying Checksum\n",
      "3e83295d72e4: Download complete\n",
      "e1d17392d33d: Verifying Checksum\n",
      "e1d17392d33d: Download complete\n",
      "11d1c96ea8b8: Verifying Checksum\n",
      "11d1c96ea8b8: Download complete\n",
      "28cab2098606: Pull complete\n",
      "eb9ca4875e99: Download complete\n",
      "40289936d166: Verifying Checksum\n",
      "40289936d166: Download complete\n",
      "bc0b9f9e7350: Verifying Checksum\n",
      "bc0b9f9e7350: Download complete\n",
      "38da30fc5f85: Verifying Checksum\n",
      "38da30fc5f85: Download complete\n",
      "6b01a270cc2c: Verifying Checksum\n",
      "6b01a270cc2c: Download complete\n",
      "2f72dce5daac: Verifying Checksum\n",
      "2f72dce5daac: Download complete\n",
      "4bf8fcfa2cf1: Verifying Checksum\n",
      "4bf8fcfa2cf1: Download complete\n",
      "6b145641fd35: Verifying Checksum\n",
      "6b145641fd35: Download complete\n",
      "6b50c2484b47: Pull complete\n",
      "e7e5cf6583cf: Verifying Checksum\n",
      "e7e5cf6583cf: Download complete\n",
      "92566ef21b5a: Download complete\n",
      "b6d251b652e5: Pull complete\n",
      "79c93d08278e: Verifying Checksum\n",
      "79c93d08278e: Download complete\n",
      "ff8f3bf6fc5f: Download complete\n",
      "3875129dc0b4: Verifying Checksum\n",
      "3875129dc0b4: Download complete\n",
      "a81501e06699: Pull complete\n",
      "d015e2eeb76c: Pull complete\n",
      "4843fc0fc222: Pull complete\n",
      "a62f4c9c11a5: Pull complete\n",
      "66b7878d2381: Download complete\n",
      "d428983292c3: Pull complete\n",
      "e6096bc2cdb2: Pull complete\n",
      "d1cf1b4c9ff9: Pull complete\n",
      "936ae117a5bd: Download complete\n",
      "434d9209a8e2: Verifying Checksum\n",
      "434d9209a8e2: Download complete\n",
      "739a441af6c5: Verifying Checksum\n",
      "739a441af6c5: Download complete\n",
      "0a6e73b9e158: Verifying Checksum\n",
      "0a6e73b9e158: Download complete\n",
      "ca8201ec17dc: Verifying Checksum\n",
      "ca8201ec17dc: Download complete\n",
      "f5180d7f71b0: Verifying Checksum\n",
      "f5180d7f71b0: Download complete\n",
      "04db425759c4: Download complete\n",
      "fb6cbf8649f8: Verifying Checksum\n",
      "fb6cbf8649f8: Download complete\n",
      "53c8d7977378: Verifying Checksum\n",
      "53c8d7977378: Download complete\n",
      "cfecc077ebde: Verifying Checksum\n",
      "cfecc077ebde: Download complete\n",
      "13167a35542b: Verifying Checksum\n",
      "13167a35542b: Download complete\n",
      "67319511d846: Verifying Checksum\n",
      "67319511d846: Download complete\n",
      "a61f0dbc7823: Download complete\n",
      "482c01fefbdc: Verifying Checksum\n",
      "482c01fefbdc: Download complete\n",
      "aa95744ff9f2: Verifying Checksum\n",
      "aa95744ff9f2: Download complete\n",
      "3a74d3c8b83b: Verifying Checksum\n",
      "3a74d3c8b83b: Download complete\n",
      "da8a3441207d: Verifying Checksum\n",
      "da8a3441207d: Download complete\n",
      "6a5489f5c0b1: Verifying Checksum\n",
      "6a5489f5c0b1: Download complete\n",
      "9e2bc2f0ba87: Verifying Checksum\n",
      "9e2bc2f0ba87: Download complete\n",
      "095fe49485f6: Verifying Checksum\n",
      "095fe49485f6: Download complete\n",
      "a61f0dbc7823: Pull complete\n",
      "efb8675bd096: Pull complete\n",
      "a89f774586d3: Pull complete\n",
      "bf30963c88c4: Pull complete\n",
      "c663aed72850: Pull complete\n",
      "5bbce2800b70: Pull complete\n",
      "da3cf001d3de: Pull complete\n",
      "411fd9a22514: Pull complete\n",
      "3e83295d72e4: Pull complete\n",
      "4d0fb79fd071: Pull complete\n",
      "40289936d166: Pull complete\n",
      "e1d17392d33d: Pull complete\n",
      "11d1c96ea8b8: Pull complete\n",
      "eb9ca4875e99: Pull complete\n",
      "92566ef21b5a: Pull complete\n",
      "bc0b9f9e7350: Pull complete\n",
      "38da30fc5f85: Pull complete\n",
      "6b01a270cc2c: Pull complete\n",
      "2f72dce5daac: Pull complete\n",
      "4bf8fcfa2cf1: Pull complete\n",
      "6b145641fd35: Pull complete\n",
      "e7e5cf6583cf: Pull complete\n",
      "79c93d08278e: Pull complete\n",
      "ff8f3bf6fc5f: Pull complete\n",
      "66b7878d2381: Pull complete\n",
      "3875129dc0b4: Pull complete\n",
      "936ae117a5bd: Pull complete\n",
      "ca8201ec17dc: Pull complete\n",
      "434d9209a8e2: Pull complete\n",
      "739a441af6c5: Pull complete\n",
      "0a6e73b9e158: Pull complete\n",
      "f5180d7f71b0: Pull complete\n",
      "04db425759c4: Pull complete\n",
      "095fe49485f6: Pull complete\n",
      "fb6cbf8649f8: Pull complete\n",
      "53c8d7977378: Pull complete\n",
      "cfecc077ebde: Pull complete\n",
      "13167a35542b: Pull complete\n",
      "67319511d846: Pull complete\n",
      "da8a3441207d: Pull complete\n",
      "482c01fefbdc: Pull complete\n",
      "aa95744ff9f2: Pull complete\n",
      "3a74d3c8b83b: Pull complete\n",
      "6a5489f5c0b1: Pull complete\n",
      "9e2bc2f0ba87: Pull complete\n",
      "Digest: sha256:d0fd1375f4c730a3fcff3b501856e087853fa627dc5c18649b72056b06c5ba03\n",
      "Status: Downloaded newer image for nvcr.io/nvidia/pytorch:21.02-py3\n",
      " ---> e52a2ed9c61e\n",
      "Step 2/8 : COPY . .\n",
      " ---> 5998e39b4dff\n",
      "Step 3/8 : RUN curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
      " ---> Running in e4e32420ed45\n",
      "Detected operating system as Ubuntu/focal.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Checking for gpg...\n",
      "Detected gpg...\n",
      "Detected apt version as 2.0.4\n",
      "Running apt-get update... done.\n",
      "Installing apt-transport-https... done.\n",
      "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
      "Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n",
      "done.\n",
      "Running apt-get update... done.\n",
      "\n",
      "The repository is setup! You can now install packages.\n",
      "Removing intermediate container e4e32420ed45\n",
      " ---> 458fd3cbb103\n",
      "Step 4/8 : RUN apt-get update -y\n",
      " ---> Running in f49f7ab66bba\n",
      "Hit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Hit:4 https://packagecloud.io/github/git-lfs/ubuntu focal InRelease\n",
      "Reading package lists...\n",
      "Removing intermediate container f49f7ab66bba\n",
      " ---> c022efb508fb\n",
      "Step 5/8 : RUN apt-get install git-lfs\n",
      " ---> Running in 37126b7d518c\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following NEW packages will be installed:\n",
      "  git-lfs\n",
      "0 upgraded, 1 newly installed, 0 to remove and 166 not upgraded.\n",
      "Need to get 7419 kB of archives.\n",
      "After this operation, 16.0 MB of additional disk space will be used.\n",
      "Get:1 https://packagecloud.io/github/git-lfs/ubuntu focal/main amd64 git-lfs amd64 3.3.0 [7419 kB]\n",
      "\u001b[91mdebconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\u001b[0m\u001b[91mdebconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "\u001b[0m\u001b[91mdpkg-preconfigure: unable to re-open stdin: \n",
      "\u001b[0mFetched 7419 kB in 0s (14.9 MB/s)\n",
      "Selecting previously unselected package git-lfs.\n",
      "(Reading database ... 36208 files and directories currently installed.)\n",
      "Preparing to unpack .../git-lfs_3.3.0_amd64.deb ...\n",
      "Unpacking git-lfs (3.3.0) ...\n",
      "Setting up git-lfs (3.3.0) ...\n",
      "Git LFS initialized.\n",
      "Removing intermediate container 37126b7d518c\n",
      " ---> b16ea8bc0bc9\n",
      "Step 6/8 : RUN pip install jupyter ipykernel\n",
      " ---> Running in 51ea4587ad57\n",
      "Collecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (5.4.3)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.2.0)\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.0.7)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.8/site-packages (from ipykernel) (6.1.11)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel) (7.20.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel) (6.1)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel) (5.0.5)\n",
      "Collecting jupyterlab-widgets~=3.0\n",
      "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
      "Collecting widgetsnbextension~=4.0\n",
      "  Downloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (4.7.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (22.0.3)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (5.1.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.9.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (2.11.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.9.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from jupyter-console->jupyter) (2.7.4)\n",
      "Collecting prompt-toolkit>=3.0.30\n",
      "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
      "Collecting qtpy>=2.0.1\n",
      "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.4.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.6.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel) (2.8.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel) (50.3.1.post20201107)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel) (0.17.0)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /opt/conda/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel) (4.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.14.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat->notebook->jupyter) (3.0.2)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /opt/conda/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook->jupyter) (1.1.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from qtpy>=2.0.1->qtconsole->jupyter) (20.9)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.10)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: parso>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel) (0.8.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.20)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->jupyter) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->jupyter) (20.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->qtpy>=2.0.1->qtconsole->jupyter) (2.4.7)\n",
      "Installing collected packages: jupyterlab-widgets, widgetsnbextension, ipywidgets, prompt-toolkit, jupyter-console, qtpy, qtconsole, jupyter\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.8\n",
      "    Uninstalling prompt-toolkit-3.0.8:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.8\n",
      "Successfully installed ipywidgets-8.0.4 jupyter-1.0.0 jupyter-console-6.6.3 jupyterlab-widgets-3.0.5 prompt-toolkit-3.0.38 qtconsole-5.4.0 qtpy-2.3.0 widgetsnbextension-4.0.5\n",
      "\u001b[91mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "jupyter-console 6.6.3 requires ipykernel>=6.14, but you'll have ipykernel 5.4.3 which is incompatible.\n",
      "jupyter-console 6.6.3 requires jupyter-client>=7.0.0, but you'll have jupyter-client 6.1.11 which is incompatible.\n",
      "jupyter-console 6.6.3 requires jupyter-core!=5.0.*,>=4.12, but you'll have jupyter-core 4.7.1 which is incompatible.\n",
      "jupyter-console 6.6.3 requires traitlets>=5.4, but you'll have traitlets 5.0.5 which is incompatible.\n",
      "\u001b[0mRemoving intermediate container 51ea4587ad57\n",
      " ---> 9cf4813be8f9\n",
      "Step 7/8 : RUN pip install transformers datasets segments-ai evaluate git-lfs tqdm==4.59\n",
      " ---> Running in 588d060e3df3\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "Collecting segments-ai\n",
      "  Downloading segments-ai-1.0.20.tar.gz (37 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "Collecting git-lfs\n",
      "  Downloading git_lfs-1.6-py2.py3-none-any.whl (5.6 kB)\n",
      "Collecting tqdm==4.59\n",
      "  Downloading tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2020.11.13)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets) (1.1.4)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Collecting types-requests\n",
      "  Downloading types_requests-2.28.11.15-py3-none-any.whl (14 kB)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from segments-ai) (3.7.4.3)\n",
      "Collecting types-Pillow\n",
      "  Downloading types_Pillow-9.4.0.17-py3-none-any.whl (46 kB)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-1.10.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2021.1)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "Collecting types-urllib3<1.27\n",
      "  Downloading types_urllib3-1.26.25.8-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Building wheels for collected packages: segments-ai\n",
      "  Building wheel for segments-ai (PEP 517): started\n",
      "  Building wheel for segments-ai (PEP 517): finished with status 'done'\n",
      "  Created wheel for segments-ai: filename=segments_ai-1.0.20-py3-none-any.whl size=37462 sha256=dd8f376df08ed1c4cba5bc298ded371d43791cb1e77d03141110d7bdcab493b2\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/29/93/1583418094fc882ce859d77d7f640117669a49dc6e69b08136\n",
      "Successfully built segments-ai\n",
      "Installing collected packages: tqdm, huggingface-hub, tokenizers, transformers, responses, pyarrow, dill, multiprocess, frozenlist, aiosignal, async-timeout, multidict, yarl, charset-normalizer, aiohttp, fsspec, xxhash, datasets, types-urllib3, types-requests, Pillow, types-Pillow, pydantic, segments-ai, evaluate, git-lfs\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.53.0\n",
      "    Uninstalling tqdm-4.53.0:\n",
      "      Successfully uninstalled tqdm-4.53.0\n",
      "\u001b[91mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "datasets 2.10.1 requires tqdm>=4.62.1, but you'll have tqdm 4.59.0 which is incompatible.\n",
      "pydantic 1.10.5 requires typing-extensions>=4.2.0, but you'll have typing-extensions 3.7.4.3 which is incompatible.\n",
      "segments-ai 1.0.20 requires numpy>=1.20, but you'll have numpy 1.19.2 which is incompatible.\n",
      "evaluate 0.4.0 requires tqdm>=4.62.1, but you'll have tqdm 4.59.0 which is incompatible.\n",
      "\u001b[0mSuccessfully installed Pillow-9.4.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 datasets-2.10.1 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 fsspec-2023.3.0 git-lfs-1.6 huggingface-hub-0.12.1 multidict-6.0.4 multiprocess-0.70.14 pyarrow-11.0.0 pydantic-1.10.5 responses-0.18.0 segments-ai-1.0.20 tokenizers-0.13.2 tqdm-4.59.0 transformers-4.26.1 types-Pillow-9.4.0.17 types-requests-2.28.11.15 types-urllib3-1.26.25.8 xxhash-3.2.0 yarl-1.8.2\n",
      "Removing intermediate container 588d060e3df3\n",
      " ---> 7d0dd603d6d1\n",
      "Step 8/8 : ENTRYPOINT [\"python\", \"train.py\"]\n",
      " ---> Running in 4a14ad9f6982\n",
      "Removing intermediate container 4a14ad9f6982\n",
      " ---> d7ebf3bb33e6\n",
      "Successfully built d7ebf3bb33e6\n",
      "Successfully tagged gcr.io/jchavezar-demo/pytorch-gpu:latest\n",
      "PUSH\n",
      "Pushing gcr.io/jchavezar-demo/pytorch-gpu:latest\n",
      "The push refers to repository [gcr.io/jchavezar-demo/pytorch-gpu]\n",
      "2eff9e687072: Preparing\n",
      "623ace6ed9f6: Preparing\n",
      "88bfe0c40c49: Preparing\n",
      "4516401b89fc: Preparing\n",
      "36a6411d2008: Preparing\n",
      "346a1bcd4587: Preparing\n",
      "f851649290ce: Preparing\n",
      "beb90e904d4a: Preparing\n",
      "367bb2e13e7d: Preparing\n",
      "3d6db62448bf: Preparing\n",
      "5ce0ebe375bc: Preparing\n",
      "5949545325cf: Preparing\n",
      "9a233e0779de: Preparing\n",
      "ae44cf14673c: Preparing\n",
      "28db8f9cf08b: Preparing\n",
      "b19adf92531d: Preparing\n",
      "10ac1dbef7b2: Preparing\n",
      "504668bebf0f: Preparing\n",
      "b4bf90161075: Preparing\n",
      "a264bb0a65b0: Preparing\n",
      "479d77d3b659: Preparing\n",
      "947c8faf5338: Preparing\n",
      "e30b0513a94a: Preparing\n",
      "d277447daf75: Preparing\n",
      "f0cdbaee8308: Preparing\n",
      "824cdc4dadfa: Preparing\n",
      "d3809e8f1041: Preparing\n",
      "986d55f29e82: Preparing\n",
      "820c28e896e2: Preparing\n",
      "32eb21776a70: Preparing\n",
      "acc06c042ab0: Preparing\n",
      "42ab5bd70f44: Preparing\n",
      "753ca7dcc041: Preparing\n",
      "60be998c0580: Preparing\n",
      "0bb9edeeb784: Preparing\n",
      "c3584d4e28a5: Preparing\n",
      "103a734af76b: Preparing\n",
      "22cb0402bd17: Preparing\n",
      "03bc95fb7bd7: Preparing\n",
      "a7e22b13f535: Preparing\n",
      "680c62fd419f: Preparing\n",
      "ca4854477648: Preparing\n",
      "1cfdd99d7129: Preparing\n",
      "cd4616f680d0: Preparing\n",
      "446ca9614a4b: Preparing\n",
      "8be8a5f6b7e9: Preparing\n",
      "935f87236f20: Preparing\n",
      "c2b5c3408626: Preparing\n",
      "b4933414ba79: Preparing\n",
      "fdf88b4e93d1: Preparing\n",
      "365643d5afc8: Preparing\n",
      "20be6eeab193: Preparing\n",
      "c9ff18121cb0: Preparing\n",
      "9b0ee6bbe33f: Preparing\n",
      "57c5672a7808: Preparing\n",
      "7db112720cb4: Preparing\n",
      "53a0d8e9e8a8: Preparing\n",
      "85b038509f66: Preparing\n",
      "5ea5e3c6332c: Preparing\n",
      "aa8804ed1436: Preparing\n",
      "867699bc5dbf: Preparing\n",
      "02473afd360b: Preparing\n",
      "dbf2c0f42a39: Preparing\n",
      "9f32931c9d28: Preparing\n",
      "753ca7dcc041: Waiting\n",
      "60be998c0580: Waiting\n",
      "0bb9edeeb784: Waiting\n",
      "c3584d4e28a5: Waiting\n",
      "103a734af76b: Waiting\n",
      "22cb0402bd17: Waiting\n",
      "03bc95fb7bd7: Waiting\n",
      "a7e22b13f535: Waiting\n",
      "680c62fd419f: Waiting\n",
      "ca4854477648: Waiting\n",
      "1cfdd99d7129: Waiting\n",
      "cd4616f680d0: Waiting\n",
      "446ca9614a4b: Waiting\n",
      "8be8a5f6b7e9: Waiting\n",
      "935f87236f20: Waiting\n",
      "c2b5c3408626: Waiting\n",
      "b4933414ba79: Waiting\n",
      "fdf88b4e93d1: Waiting\n",
      "365643d5afc8: Waiting\n",
      "20be6eeab193: Waiting\n",
      "c9ff18121cb0: Waiting\n",
      "9b0ee6bbe33f: Waiting\n",
      "57c5672a7808: Waiting\n",
      "7db112720cb4: Waiting\n",
      "53a0d8e9e8a8: Waiting\n",
      "85b038509f66: Waiting\n",
      "5ea5e3c6332c: Waiting\n",
      "aa8804ed1436: Waiting\n",
      "867699bc5dbf: Waiting\n",
      "346a1bcd4587: Waiting\n",
      "f851649290ce: Waiting\n",
      "beb90e904d4a: Waiting\n",
      "367bb2e13e7d: Waiting\n",
      "3d6db62448bf: Waiting\n",
      "5ce0ebe375bc: Waiting\n",
      "5949545325cf: Waiting\n",
      "9a233e0779de: Waiting\n",
      "ae44cf14673c: Waiting\n",
      "28db8f9cf08b: Waiting\n",
      "b19adf92531d: Waiting\n",
      "10ac1dbef7b2: Waiting\n",
      "02473afd360b: Waiting\n",
      "dbf2c0f42a39: Waiting\n",
      "504668bebf0f: Waiting\n",
      "b4bf90161075: Waiting\n",
      "a264bb0a65b0: Waiting\n",
      "479d77d3b659: Waiting\n",
      "824cdc4dadfa: Waiting\n",
      "947c8faf5338: Waiting\n",
      "d3809e8f1041: Waiting\n",
      "e30b0513a94a: Waiting\n",
      "986d55f29e82: Waiting\n",
      "d277447daf75: Waiting\n",
      "f0cdbaee8308: Waiting\n",
      "820c28e896e2: Waiting\n",
      "42ab5bd70f44: Waiting\n",
      "32eb21776a70: Waiting\n",
      "acc06c042ab0: Waiting\n",
      "9f32931c9d28: Waiting\n",
      "4516401b89fc: Pushed\n",
      "88bfe0c40c49: Pushed\n",
      "36a6411d2008: Pushed\n",
      "346a1bcd4587: Pushed\n",
      "623ace6ed9f6: Pushed\n",
      "f851649290ce: Pushed\n",
      "367bb2e13e7d: Pushed\n",
      "beb90e904d4a: Pushed\n",
      "3d6db62448bf: Pushed\n",
      "5ce0ebe375bc: Pushed\n",
      "28db8f9cf08b: Pushed\n",
      "9a233e0779de: Pushed\n",
      "b19adf92531d: Pushed\n",
      "10ac1dbef7b2: Pushed\n",
      "b4bf90161075: Pushed\n",
      "5949545325cf: Pushed\n",
      "2eff9e687072: Pushed\n",
      "479d77d3b659: Pushed\n",
      "ae44cf14673c: Pushed\n",
      "a264bb0a65b0: Pushed\n",
      "947c8faf5338: Pushed\n",
      "824cdc4dadfa: Pushed\n",
      "f0cdbaee8308: Pushed\n",
      "986d55f29e82: Pushed\n",
      "820c28e896e2: Pushed\n",
      "32eb21776a70: Pushed\n",
      "d3809e8f1041: Pushed\n",
      "e30b0513a94a: Pushed\n",
      "753ca7dcc041: Pushed\n",
      "60be998c0580: Pushed\n",
      "0bb9edeeb784: Pushed\n",
      "504668bebf0f: Pushed\n",
      "c3584d4e28a5: Pushed\n",
      "d277447daf75: Pushed\n",
      "acc06c042ab0: Pushed\n",
      "a7e22b13f535: Pushed\n",
      "22cb0402bd17: Pushed\n",
      "ca4854477648: Pushed\n",
      "680c62fd419f: Pushed\n",
      "cd4616f680d0: Pushed\n",
      "446ca9614a4b: Pushed\n",
      "1cfdd99d7129: Pushed\n",
      "935f87236f20: Pushed\n",
      "c2b5c3408626: Pushed\n",
      "b4933414ba79: Pushed\n",
      "fdf88b4e93d1: Pushed\n",
      "8be8a5f6b7e9: Pushed\n",
      "20be6eeab193: Pushed\n",
      "c9ff18121cb0: Pushed\n",
      "9b0ee6bbe33f: Pushed\n",
      "57c5672a7808: Pushed\n",
      "7db112720cb4: Pushed\n",
      "53a0d8e9e8a8: Pushed\n",
      "85b038509f66: Pushed\n",
      "5ea5e3c6332c: Pushed\n",
      "03bc95fb7bd7: Pushed\n",
      "aa8804ed1436: Pushed\n",
      "02473afd360b: Layer already exists\n",
      "dbf2c0f42a39: Layer already exists\n",
      "9f32931c9d28: Layer already exists\n",
      "867699bc5dbf: Pushed\n",
      "42ab5bd70f44: Pushed\n",
      "103a734af76b: Pushed\n",
      "365643d5afc8: Pushed\n",
      "latest: digest: sha256:5295e221aca2ac31c57cae688dfe7375653d6436a0488b46b3b5d86b419191c2 size: 13774\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                        IMAGES                                       STATUS\n",
      "c7b2845a-f93b-4a22-8be2-59fef2174550  2023-03-08T04:19:53+00:00  18M39S    gs://jchavezar-demo_cloudbuild/source/1678249191.947235-eea1ad046b4f4be48997bbcc0a24d369.tgz  gcr.io/jchavezar-demo/pytorch-gpu (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit -t $TRAIN_IMAGE_URI source/."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Job (CustomJob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sockcop/.local/lib/python3.9/site-packages/google/auth/_default.py:83: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/569083142710/locations/us-central1/customJobs/3725771704216059904\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/569083142710/locations/us-central1/customJobs/3725771704216059904')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/3725771704216059904?project=569083142710\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/3725771704216059904 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform as aip\n",
    "\n",
    "aip.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION)\n",
    "\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        'machine_spec' : {\n",
    "            'machine_type': 'a2-highgpu-1g',\n",
    "            'accelerator_type': 'NVIDIA_TESLA_A100',\n",
    "            'accelerator_count': 1\n",
    "        },\n",
    "        'replica_count': 1,\n",
    "        \n",
    "        'container_spec': {\n",
    "            'image_uri': TRAIN_IMAGE_URI,\n",
    "            'args': [\n",
    "                '--token='+TOKEN,\n",
    "                '--model_name='+MODEL_NAME,\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "job = aip.CustomJob(\n",
    "    display_name = 'image_seg_custom_py',\n",
    "    worker_pool_specs = worker_pool_specs,\n",
    "    staging_bucket = STAGING_URI\n",
    ")\n",
    "\n",
    "model = job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sockcop/vertex-ai-samples/vertex-custom-ml/pytorch/custom_jobs/image_segmentation\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
