{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562aa9cd-ee99-4676-9806-a6df224f0b18",
   "metadata": {},
   "source": [
    "![](../../images/ml_flow_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d852287-c347-4c93-a151-3e872f1d929f",
   "metadata": {},
   "source": [
    "## Pipelines Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1ac78-9e90-4a3d-b051-baf51cc9aaa7",
   "metadata": {},
   "source": [
    "### Create Code/Folder Structure and Set Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640a2ead-cc84-443b-b8f4-7ad245ab0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jchavezar-demo'\n",
    "TRAIN_IMAGE = 'gcr.io/jchavezar-demo/pytorch-custom-random-t:v2'\n",
    "PREDICTION_IMAGE = 'gcr.io/jchavezar-demo/pytorch-custom-random-p:v2'\n",
    "STAGING_BUCKET = 'gs://vtx-staging'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e144478-206d-43df-b8b1-426d10b92a85",
   "metadata": {},
   "source": [
    "#### Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d53a77-361f-4cf3-bb6d-9de1fd2472bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr training\n",
    "!mkdir training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c4767e-4758-46d3-b143-58789f16d6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training/train.py\n",
    "#%%\n",
    "import pandas as pd\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "\n",
    "train = pd.read_csv('gs://vtx-datasets-public/pytorch_tabular/synthetic/train.csv')\n",
    "test = pd.read_csv('gs://vtx-datasets-public/pytorch_tabular/synthetic/test.csv')\n",
    "val = pd.read_csv('gs://vtx-datasets-public/pytorch_tabular/synthetic/val.csv')\n",
    "\n",
    "cat_col_names = [col for col in train.columns if 'cat' in col]\n",
    "num_col_names = [col for col in train.columns if 'num' in col]\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    accelerator=\"auto\", # can be 'cpu','gpu', 'tpu', or 'ipu' \n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", # No additional layer in head, just a mapping layer to output_dim\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__ # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"32-16\", # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\", # Activation between each layers\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\",\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    "    learning_rate = 1e-3\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=train, validation=val)\n",
    "tabular_model.save_model('/gcs/vtx-models/pytorch/tabular_random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0def7e53-c338-44c6-8650-dd625ba74b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile training/Dockerfile\n",
    "FROM pytorch/pytorch:1.12.1-cuda11.3-cudnn8-devel\n",
    "\n",
    "COPY . .\n",
    "RUN pip install pytorch_tabular[extra]\n",
    "RUN pip install gcsfs\n",
    "\n",
    "ENTRYPOINT [\"python\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fff6d-f878-4cc4-af76-e63439d31b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit -t $TRAIN_IMAGE training/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12b1d24c-d486-414c-a3b5-1f52e493513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package google_cloud_pipeline_components.v1.model.upload_model in google_cloud_pipeline_components.v1.model:\n",
      "\n",
      "NAME\n",
      "    google_cloud_pipeline_components.v1.model.upload_model - Google Cloud Pipeline V2 Model Upload Component.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    component\n",
      "\n",
      "FILE\n",
      "    /opt/conda/lib/python3.7/site-packages/google_cloud_pipeline_components/v1/model/upload_model/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.upload_model.component.UnmanagedContainerModel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c5a4b-44cc-4d10-9eca-ef3eb1a337d3",
   "metadata": {},
   "source": [
    "#### Prediction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7db44de-d37e-441f-b894-4e740e86a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr prediction\n",
    "!mkdir prediction\n",
    "!mkdir prediction/app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ea5310f-4a00-4a51-9f0a-c0cabbf7937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prediction/app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prediction/app/main.py\n",
    "\n",
    "#%%\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from starlette.responses import JSONResponse\n",
    "from fastapi import Request, FastAPI\n",
    "from pytorch_tabular import TabularModel\n",
    "\n",
    "app = FastAPI()\n",
    "#columns = pd.read_csv('gs://vtx-datasets-public/pytorch_tabular/synthetic/train.csv', nrows=0).iloc[:,:-1].columns.to_list()\n",
    "loaded_model = TabularModel.load_from_checkpoint(\"tabular_random\")\n",
    "#%%\n",
    "@app.get('/health_check')\n",
    "def health():\n",
    "    return 200\n",
    "if os.environ.get('AIP_PREDICT_ROUTE') is not None:\n",
    "    method = os.environ['AIP_PREDICT_ROUTE']\n",
    "else:\n",
    "    method = '/predict'\n",
    "\n",
    "@app.post(method)\n",
    "async def predict(request: Request):\n",
    "    print(\"----------------- PREDICTING -----------------\")\n",
    "    body = await request.json()\n",
    "    instances = body[\"instances\"]\n",
    "    data_pred = pd.DataFrame.from_dict(instances)\n",
    "    outputs = loaded_model.predict(data_pred)\n",
    "    response = outputs['prediction'].tolist()\n",
    "    print(\"----------------- OUTPUTS -----------------\")\n",
    "    return JSONResponse({\n",
    "        \"predictions\": {\"probability\": response}\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbc29947-a0ab-4811-8c16-38396823b749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prediction/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile prediction/Dockerfile\n",
    "\n",
    "FROM pytorch/pytorch:1.12.1-cuda11.3-cudnn8-devel\n",
    "\n",
    "COPY app /app\n",
    "WORKDIR /app\n",
    "\n",
    "RUN pip install pytorch_tabular[extra]\n",
    "RUN pip install uvicorn fastapi\n",
    "RUN pip install gcsfs\n",
    "\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa964a2-f340-4c04-93fa-874017ff0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp -r gs://vtx-models/pytorch/tabular_random prediction/app/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e1a78-caaa-44c6-b216-e73acf182679",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit -t $PREDICTION_IMAGE prediction/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43377ebd-b492-428f-99d7-504f47a26dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfp                                   2.0.0b13\n",
      "kfp-pipeline-spec                     0.2.0\n",
      "kfp-server-api                        2.0.0a6\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3439cb0-c1fd-468d-b658-5381d5d01d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-cloud-pipeline-components      2.0.0b1\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e9928-1aa9-4adf-ad77-7050517e8367",
   "metadata": {},
   "source": [
    "### Data Extraction and Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dedc4e14-db5a-4a09-bf91-06c78e61e3b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Constant argument inputs must be one of type ['String', 'Integer', 'Float', 'Boolean', 'List', 'Dict'] Got: <kfp.components.pipeline_task.PipelineTask object at 0x7f63091730d0> of type <class 'kfp.components.pipeline_task.PipelineTask'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12419/2769599403.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m def pipeline(\n\u001b[1;32m     37\u001b[0m     \u001b[0mproject_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdisplay_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m ):\n\u001b[1;32m     40\u001b[0m     train_task = custom_job.CustomTrainingJobOp(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kfp/components/pipeline_context.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(func, name, description, pipeline_root)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcomponent_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_graph_component_from_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kfp/components/component_factory.py\u001b[0m in \u001b[0;36mcreate_graph_component_from_func\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mcomponent_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponent_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mpipeline_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponent_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kfp/components/graph_component.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, component_spec, pipeline_func, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         with pipeline_context.Pipeline(\n\u001b[1;32m     58\u001b[0m                 self.component_spec.name) as dsl_pipeline:\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mpipeline_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdsl_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12419/2769599403.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(project_id, display_name)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mdisplay_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{display_name}-model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0munmanaged_container_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimporter_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m#explanation_parameters=parameters,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m#explanation_metadata=EXPLANATION_METADATA,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kfp/components/base_component.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         return pipeline_task.PipelineTask(\n\u001b[1;32m    101\u001b[0m             \u001b[0mcomponent_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kfp/components/pipeline_task.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, component_spec, args)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mexpected_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 error_message_prefix=(\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;34mf'Incompatible argument passed to the input '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                     f'{input_name!r} of component {component_spec.name!r}: '),\n\u001b[1;32m     90\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kfp/components/types/type_utils.py\u001b[0m in \u001b[0;36mverify_type_compatibility\u001b[0;34m(given_value, expected_spec, error_message_prefix, checks_input)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# extract and normalize types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mexpected_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpected_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0mgiven_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_type_string_from_component_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgiven_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mgiven_is_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_parameter_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgiven_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kfp/components/types/type_utils.py\u001b[0m in \u001b[0;36m_get_type_string_from_component_argument\u001b[0;34m(argument_value)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     raise ValueError(\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;34mf'Constant argument inputs must be one of type {list(_TYPE_TO_TYPE_NAME.values())} Got: {argument_value!r} of type {type(argument_value)!r}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Constant argument inputs must be one of type ['String', 'Integer', 'Float', 'Boolean', 'List', 'Dict'] Got: <kfp.components.pipeline_task.PipelineTask object at 0x7f63091730d0> of type <class 'kfp.components.pipeline_task.PipelineTask'>."
     ]
    }
   ],
   "source": [
    "from google_cloud_pipeline_components.v1 import custom_job, model\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "google_cloud_pipeline_components.v1.model\n",
    "from google_cloud_pipeline_components.aiplatform import ModelUploadOp\n",
    "from kfp.dsl import pipeline, importer\n",
    "\n",
    "## Worker pool spec for training\n",
    "worker_pool_specs = [\n",
    "        {\n",
    "            \"machine_spec\": {\n",
    "                \"machine_type\": \"n1-standard-4\",\n",
    "                \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "                \"accelerator_count\": 1,\n",
    "            },\n",
    "            \"replica_count\": 1,\n",
    "            \"container_spec\": {\n",
    "                \"image_uri\": TRAIN_IMAGE,\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "## Prediction image definition\n",
    "importer_spec = importer(\n",
    "    artifact_uri= \"gs://vtx-models/pytorch/tabular_random\",\n",
    "    artifact_class=model.upload_model.component.UnmanagedContainerModel, \n",
    "    metadata={\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": PREDICTION_IMAGE,\n",
    "            \"health_route\": \"/health_check\",\n",
    "            \"ports\": [8080]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "@pipeline(name=\"pytorch-tabular-gpu\")\n",
    "def pipeline(\n",
    "    project_id: str,\n",
    "    display_name: str,\n",
    "):\n",
    "    train_task = custom_job.CustomTrainingJobOp(\n",
    "        display_name=f\"{display_name}-train\",\n",
    "        project=project_id,\n",
    "        worker_pool_specs=worker_pool_specs\n",
    "    )\n",
    "    upload_task = model.ModelUploadOp(\n",
    "        display_name=f\"{display_name}-model\",\n",
    "        project=project_id,\n",
    "        unmanaged_container_model=importer_spec,\n",
    "        #explanation_parameters=parameters,\n",
    "        #explanation_metadata=EXPLANATION_METADATA,\n",
    "    ).after(train_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b59b347-b4c8-4ea9-8194-f6be6d3bbd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24375/3486598725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m compiler.Compiler().compile(\n\u001b[1;32m      5\u001b[0m     \u001b[0mpipeline_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     package_path='pytorch-tabular-pipe.yaml')\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, pipeline_func, package_path, pipeline_name, pipeline_parameters, type_check)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py\u001b[0m in \u001b[0;36m_create_pipeline_v2\u001b[0;34m(self, pipeline_func, pipeline_name, pipeline_parameters_override)\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24375/998016792.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(project_id, display_name)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mworker_pool_specs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworker_pool_specs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     )\n\u001b[0;32m---> 45\u001b[0;31m     upload_task = model.ModelUploadOp(\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mdisplay_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Compile File\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path='pytorch-tabular-pipe.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c768976-5729-4da8-a432-b321f044588b",
   "metadata": {},
   "source": [
    "## [OPTIONAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da333e6-b561-4c56-a77b-4bfc85c02b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Template:\n",
    "from kfp.registry import RegistryClient\n",
    "\n",
    "client = RegistryClient(host=f\"https://us-central1-kfp.pkg.dev/jchavezar-demo/simple-samples-repo\")\n",
    "\n",
    "## Upload Template\n",
    "\n",
    "templateName, versionName = client.upload_pipeline(\n",
    "  file_name=\"pytorch-tabular-pipe.yaml\",\n",
    "  tags=[\"v1\", \"latest\"],\n",
    "  extra_headers={\"description\":\"This is an example pipeline template.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457b9e3-7b5a-47d5-94bd-f16412d7fcc3",
   "metadata": {},
   "source": [
    "## Creating Pipelines from Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e793a74a-a89b-4ba0-80ec-22cbb1c311ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Initialize the aiplatform package\n",
    "aiplatform.init(\n",
    "    project=\"jchavezar-demo\",\n",
    "    location='us-central1',\n",
    "    staging_bucket=\"gs://vtx-staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b1bd7f-8262-4ed3-a74c-2d0251168e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/569083142710/locations/us-central1/pipelineJobs/pytorch-tabular-gpu-20230327140940\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/569083142710/locations/us-central1/pipelineJobs/pytorch-tabular-gpu-20230327140940')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/pytorch-tabular-gpu-20230327140940?project=569083142710\n"
     ]
    }
   ],
   "source": [
    "# Create a job via version id.\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"pytorch-tabular-latest\",\n",
    "    template_path=\"pytorch-tabular-pipe.json\",\n",
    "    parameter_values={\n",
    "        \"project_id\": PROJECT_ID\n",
    "    },\n",
    ")\n",
    "job.submit(experiment='pytorch-tabular-pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82fbc9-dd4d-4cbf-bd06-271c09952305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e1eb5ca-fae1-4d08-a492-d6e9d4f2491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/569083142710/locations/us-central1/pipelineJobs/simple-testing-20230322170958\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/569083142710/locations/us-central1/pipelineJobs/simple-testing-20230322170958')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/simple-testing-20230322170958?project=569083142710\n"
     ]
    }
   ],
   "source": [
    "# Create a job via tag and with different \n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"simple-sample-latest\",\n",
    "    template_path=\"https://us-central1-kfp.pkg.dev/jchavezar-demo/simple-samples-repo/simple-testing/v1\",\n",
    "    parameter_values={\"dataset\": \"gs://vtx-datasets-public/pytorch_tabular/synthetic/test.csv\"}\n",
    ")\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1037c22b-cd3f-4df2-8675-9590a98cb013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/datasets/_openml.py:421: UserWarning: Multiple active versions of the dataset matching the name credit-g exist. Versions may be fundamentally different, returning version 1.\n",
      "  \" {version}.\".format(name=name, version=res[0][\"version\"])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(\"credit-g\")  # get the credit data from OpenML\n",
    "X_raw = data.data  # features (pandas DataFrame)\n",
    "y_raw = data.target  # labels (pandas Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa47630b-6b5d-40a0-baa6-c3b266ce8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw['target']=y_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "867850b3-8dd4-4188-ba72-af220c8b74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc6811e-5dac-4e55-be9a-26189b3b6089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
