{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize (Variables and Libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"vtxdemos\"\n",
    "STAGING_FOLDER_URI =  \"gs://vtxdemos-staging\"\n",
    "IMAGE_URI = \"gcr.io/vtxdemos/tensorflow-gpu-nlp:v1\"\n",
    "MODEL_URI = \"gs://vtxdemos-models/nlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as aip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Folder Structure for Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr training\n",
    "!mkdir training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training/train.py\n",
    "#%%\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from google.cloud import bigquery\n",
    "import tensorflow_datasets as tfds\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "\n",
    "client = bigquery.Client(project=\"vtxdemos\")\n",
    "\n",
    "## Loading testing dataset from bigquery\n",
    "sql = \"select * from `public.train_nlp`\"\n",
    "train_df = client.query(sql).to_dataframe()\n",
    "train_examples = np.array([i.encode('utf-8') for i in train_df['text']], dtype=\"object\")\n",
    "train_labels = train_df['labels'].to_numpy(dtype=int)\n",
    "\n",
    "## Loading testing dataset from bigquery\n",
    "sql = \"select * from `vtxdemos.public.train_nlp`\"\n",
    "test_df = client.query(sql).to_dataframe()\n",
    "test_examples = np.array([i.encode('utf-8') for i in test_df['text']], dtype=\"object\")\n",
    "test_labels = test_df['labels'].to_numpy(dtype=int)\n",
    "\n",
    "## Load pre-trained model (BERT)\n",
    "model = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "hub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=True)\n",
    "\n",
    "## Splitting datasets\n",
    "x_val = train_examples[:10000]\n",
    "partial_x_train = train_examples[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]\n",
    "\n",
    "## Create new nn layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\n",
    "\n",
    "#%%\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[callback])\n",
    "model.save(os.getenv('AIP_MODEL_DIR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile training/requirements.txt\n",
    "tensorflow==2.11.0\n",
    "tensorflow_hub\n",
    "tensorflow-datasets\n",
    "numpy\n",
    "pandas\n",
    "google-cloud-bigquery\n",
    "db-dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile training/Dockerfile\n",
    "FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04\n",
    "ARG DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "COPY train.py train.py\n",
    "COPY requirements.txt requirements.txt\n",
    "RUN apt update -y\n",
    "RUN apt-get install -y python3.10 && \\\n",
    "     apt-get install -y python3-pip\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "CMD [\"python3\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t $IMAGE_URI training/.\n",
    "!docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/254356041555/locations/us-central1/customJobs/5842437965434847232\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/254356041555/locations/us-central1/customJobs/5842437965434847232')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/5842437965434847232?project=254356041555\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "2\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "3\n",
      "CustomJob projects/254356041555/locations/us-central1/customJobs/5842437965434847232 current state:\n",
      "4\n",
      "CustomJob run completed. Resource name: projects/254356041555/locations/us-central1/customJobs/5842437965434847232\n"
     ]
    }
   ],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=STAGING_FOLDER_URI)\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\" : \"n1-standard-8\",\n",
    "            \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "            \"accelerator_count\": 1\n",
    "        },\n",
    "        \"replica_count\": \"1\",\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\" : IMAGE_URI\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "job = aip.CustomJob(\n",
    "    display_name=\"tensorflow-gpu-nlp\",\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=MODEL_URI,\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Model From Google Cloud Storage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Container for Vertex Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr prediction\n",
    "!mkdir prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!writefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/254356041555/locations/us-central1/models/8938671093028225024/operations/8272465796484038656\n",
      "Model created. Resource name: projects/254356041555/locations/us-central1/models/8938671093028225024@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/254356041555/locations/us-central1/models/8938671093028225024@1')\n"
     ]
    }
   ],
   "source": [
    "model = aip.Model.upload(\n",
    "    display_name = 'cb-nlp-tf2',\n",
    "    serving_container_image_uri = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest\",\n",
    "    artifact_uri = f'{MODEL_URI}/model',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/254356041555/locations/us-central1/endpoints/5500632373391261696/operations/4629053697941307392\n",
      "Endpoint created. Resource name: projects/254356041555/locations/us-central1/endpoints/5500632373391261696\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/254356041555/locations/us-central1/endpoints/5500632373391261696')\n",
      "Deploying model to Endpoint : projects/254356041555/locations/us-central1/endpoints/5500632373391261696\n",
      "Deploy Endpoint model backing LRO: projects/254356041555/locations/us-central1/endpoints/5500632373391261696/operations/7565400654986870784\n",
      "Endpoint model deployed. Resource name: projects/254356041555/locations/us-central1/endpoints/5500632373391261696\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name = 'cb-nlp-tf2-end',\n",
    "    traffic_percentage = 100,\n",
    "    machine_type = 'n1-standard-4',\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[-0.768929064]], deployed_model_id='6501018629876744192', model_version_id='1', model_resource_name='projects/254356041555/locations/us-central1/models/8938671093028225024', explanations=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "string=\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
    "request = {\"instances\": np.array([string.encode('utf-8')], dtype='object')}\n",
    "endpoint.predict(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/prediction.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/254356041555/locations/us-central1/endpoints/5500632373391261696\n",
      "Undeploy Endpoint model backing LRO: projects/254356041555/locations/us-central1/endpoints/5500632373391261696/operations/8779120754563219456\n",
      "Endpoint model undeployed. Resource name: projects/254356041555/locations/us-central1/endpoints/5500632373391261696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f14ac687510> \n",
       "resource name: projects/254356041555/locations/us-central1/endpoints/5500632373391261696"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cleaning\n",
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Endpoint : projects/254356041555/locations/us-central1/endpoints/5500632373391261696\n",
      "Delete Endpoint  backing LRO: projects/254356041555/locations/us-central1/operations/9197392569955254272\n",
      "Endpoint deleted. . Resource name: projects/254356041555/locations/us-central1/endpoints/5500632373391261696\n"
     ]
    }
   ],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0410 20:25:17.803986897   31051 backup_poller.cc:136]                 Run client channel backup poller: UNKNOWN:pollset_work {created_time:\"2023-04-10T20:25:17.803869467+00:00\", children:[UNKNOWN:Bad file descriptor {created_time:\"2023-04-10T20:25:17.803746682+00:00\", errno:9, os_error:\"Bad file descriptor\", syscall:\"epoll_wait\"}]}\n"
     ]
    }
   ],
   "source": [
    "!rm -fr training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vertex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
