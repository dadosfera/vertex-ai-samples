{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../../../images/python-distribution-package-tabclass.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jchavezar-demo' # @param {type:\"string\"}\n",
    "REGION = 'us-central1' # @param {type:\"string\"}\n",
    "#DATASETS_URI = 'gs://vtx-datasets-public/ecommerce' # @param {type:\"string\"}\n",
    "MODEL_URI = 'gs://vtx-models/flower_photos/tpu' # @param {type:\"string\"}\n",
    "STAGING_URI = 'gs://vtx-staging/flower_photos/tpu' # @param {type:\"string\"}\n",
    "TRAIN_IMAGE_URI = 'us-docker.pkg.dev/vertex-ai/training/tf-tpu.2-8:latest' # @param {type:\"string\"}\n",
    "PREDICTION_IMAGE_URI = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest' # @param {type:\"string\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as aip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code Wrap it in Python Distribution Package File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr source\n",
    "!mkdir -p source/trainer\n",
    "!touch source/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source/trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source/trainer/train.py\n",
    "import os, sys, math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "try: # detect TPUs\n",
    "    #tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
    "    #strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError: # detect GPUs\n",
    "    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
    "    tpu = \"\"\n",
    "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "GCS_PATTERN = 'gs://vtx-datasets-public/flower_photos_tfrecords-jpeg-192x192-2/*.tfrec'\n",
    "IMAGE_SIZE = [192, 192]\n",
    "\n",
    "if tpu:\n",
    "    BATCH_SIZE = 16*strategy.num_replicas_in_sync  # A TPU has 8 cores so this will be 128\n",
    "else:\n",
    "    BATCH_SIZE = 32  # On Colab/GPU, a higher batch size does not help and sometimes does not fit on the GPU (OOM)\n",
    "\n",
    "VALIDATION_SPLIT = 0.19\n",
    "CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'] # do not change, maps to the labels in the data (folder names)\n",
    "\n",
    "# splitting data files between training and validation\n",
    "filenames = tf.io.gfile.glob(GCS_PATTERN)\n",
    "split = int(len(filenames) * VALIDATION_SPLIT)\n",
    "training_filenames = filenames[split:]\n",
    "validation_filenames = filenames[:split]\n",
    "validation_steps = int(3670 // len(filenames) * len(validation_filenames)) // BATCH_SIZE\n",
    "steps_per_epoch = int(3670 // len(filenames) * len(training_filenames)) // BATCH_SIZE\n",
    "\n",
    "## Utils\n",
    "def dataset_to_numpy_util(dataset, N):\n",
    "    dataset = dataset.batch(N)\n",
    "    # In eager mode, iterate in the Datset directly.\n",
    "    for images, labels in dataset:\n",
    "        numpy_images = images.numpy()\n",
    "        numpy_labels = labels.numpy()\n",
    "        break;\n",
    "    \n",
    "    return numpy_images, numpy_labels\n",
    "\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n",
    "        \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    image = tf.io.decode_jpeg(example['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size will be needed for TPU\n",
    "    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n",
    "    one_hot_class = tf.reshape(one_hot_class, [5])\n",
    "    return image, one_hot_class\n",
    "\n",
    "def load_dataset(filenames):\n",
    "    # read from TFRecords. For optimal performance, read from multiple\n",
    "    # TFRecord files at once and set the option experimental_deterministic = False\n",
    "    # to allow order-altering optimizations.\n",
    "\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_batched_dataset(filenames, train=False):\n",
    "    dataset = load_dataset(filenames)\n",
    "    dataset = dataset.cache() # This dataset fits in RAM\n",
    "    if train:\n",
    "        # Best practices for Keras:\n",
    "        # Training dataset: repeat then batch\n",
    "        # Evaluation dataset: do not repeat\n",
    "        dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    # should shuffle too but this dataset was well shuffled on disk already\n",
    "    return dataset\n",
    "\n",
    "# instantiate the datasets\n",
    "training_dataset = get_batched_dataset(training_filenames, train=True)\n",
    "validation_dataset = get_batched_dataset(validation_filenames, train=False)\n",
    "\n",
    "some_flowers, some_labels = dataset_to_numpy_util(load_dataset(validation_filenames), 160)\n",
    "\n",
    "with strategy.scope(): # this line is all that is needed to run on TPU (or multi-GPU, ...)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, filters=16, padding='same', activation='relu', input_shape=[*IMAGE_SIZE, 3]),\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, filters=30, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, filters=60, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, filters=90, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, filters=110, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "        tf.keras.layers.Conv2D(kernel_size=3, filters=130, padding='same', activation='relu'),\n",
    "        tf.keras.layers.Conv2D(kernel_size=1, filters=40, padding='same', activation='relu'),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss= 'categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    EPOCHS = 20\n",
    "    \n",
    "    history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
    "                        validation_data=validation_dataset)\n",
    "    tf.saved_model.save(model, os.environ['AIP_MODEL_DIR'])\n",
    "    #model.save(os.environ['AIP_MODEL_DIR'])\n",
    "    \n",
    "    #Storing metrics/artifacts\n",
    "    print(os.listdir('/gcs/vtx-models/'))\n",
    "\n",
    "    with open('/gcs/vtx-models/flower_photos/tpu/metrics', 'wb') as file:\n",
    "        pickle.dump(history.history,  file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source/setup.py\n",
    "from setuptools import setup\n",
    "from setuptools import find_packages\n",
    "\n",
    "setup(\n",
    "    name = 'trainer',\n",
    "    packages = find_packages(),\n",
    "    description='Training Package'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "k = {\"er\":\"wer\"}\n",
    "\n",
    "with open('/tmp/dict', 'wb') as f:\n",
    "    pickle.dump(k, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/dict\", 'rb') as f:\n",
    "    hist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'er': 'wer'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source/\n",
      "source/trainer/\n",
      "source/trainer/__init__.py\n",
      "source/trainer/train.py\n",
      "source/setup.py\n",
      "Copying file://source.tar.gz...\n",
      "/ [1 files][  2.4 KiB/  2.4 KiB]                                                \n",
      "Operation completed over 1 objects/2.4 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!rm -f source.tar source.tar.gz\n",
    "!tar cvf source.tar source\n",
    "!gzip source.tar\n",
    "# Copy python package with training code to Google Cloud Storage\n",
    "!gsutil cp source.tar.gz {MODEL_URI}/packages/source.tar.gz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex AI Training Using CustomJob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*More Information about CustoJob Library here: https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob*\n",
    "\n",
    "*For worker_pool_specs definition: https://cloud.google.com/vertex-ai/docs/reference/rest/v1/CustomJobSpec#WorkerPoolSpec*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sockcop/.local/lib/python3.9/site-packages/google/auth/_default.py:83: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/569083142710/locations/us-central1/customJobs/262442018116993024\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/569083142710/locations/us-central1/customJobs/262442018116993024')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/262442018116993024?project=569083142710\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/262442018116993024 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "# Initialize Vertex\n",
    "aip.init(project=PROJECT_ID)\n",
    "\n",
    "# Job Definition\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        'machine_spec' : {\n",
    "            'machine_type': 'cloud-tpu',\n",
    "            'accelerator_type': 'TPU_V2',\n",
    "            'accelerator_count': 8\n",
    "        },\n",
    "        'replica_count': 1,\n",
    "        'python_package_spec': {\n",
    "            'executor_image_uri': TRAIN_IMAGE_URI,\n",
    "            'package_uris': [MODEL_URI+'/packages/source.tar.gz'],\n",
    "            'python_module': 'trainer.train',\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "job = aip.CustomJob(\n",
    "    display_name = 'flower_photos_tf-tpu',\n",
    "    worker_pool_specs = worker_pool_specs,\n",
    "    base_output_dir = MODEL_URI,\n",
    "    staging_bucket = STAGING_URI\n",
    ")\n",
    "\n",
    "# Job Execution\n",
    "model = job.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Model to Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sockcop/.local/lib/python3.9/site-packages/google/auth/_default.py:83: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/569083142710/locations/us-central1/models/8304974163429294080/operations/9115495446360358912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sockcop/.local/lib/python3.9/site-packages/google/auth/_default.py:83: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/home/sockcop/.local/lib/python3.9/site-packages/google/auth/_default.py:83: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created. Resource name: projects/569083142710/locations/us-central1/models/8304974163429294080@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/569083142710/locations/us-central1/models/8304974163429294080@1')\n"
     ]
    }
   ],
   "source": [
    "model_reg = aip.Model.upload(\n",
    "    display_name = 'flower_photos_tf-tpu',\n",
    "    serving_container_image_uri = PREDICTION_IMAGE_URI,\n",
    "    artifact_uri = f'{MODEL_URI}/model',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model for Online Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = model_reg.deploy(\n",
    "    deployed_model_display_name = 'flower_photos_tf_ep_dep-v1',\n",
    "    traffic_percentage = 100,\n",
    "    machine_type = 'n1-standard-4',\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "IMAGE_SIZE = [192, 192]\n",
    "\n",
    "\n",
    "validation_filenames = ['gs://flowers-public/tfrecords-jpeg-192x192-2/flowers00-230.tfrec',\n",
    " 'gs://flowers-public/tfrecords-jpeg-192x192-2/flowers01-230.tfrec',\n",
    " 'gs://flowers-public/tfrecords-jpeg-192x192-2/flowers02-230.tfrec']\n",
    "\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n",
    "        \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    image = tf.io.decode_jpeg(example['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size will be needed for TPU\n",
    "    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n",
    "    one_hot_class = tf.reshape(one_hot_class, [5])\n",
    "    return image, one_hot_class\n",
    "\n",
    "\n",
    "def load_dataset(filenames):\n",
    "  # read from TFRecords. For optimal performance, read from multiple\n",
    "  # TFRecord files at once and set the option experimental_deterministic = False\n",
    "  # to allow order-altering optimizations.\n",
    "\n",
    "  option_no_order = tf.data.Options()\n",
    "  option_no_order.experimental_deterministic = False\n",
    "\n",
    "  dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "  dataset = dataset.with_options(option_no_order)\n",
    "  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "  return dataset\n",
    "\n",
    "def dataset_to_numpy_util(dataset, N):\n",
    "  dataset = dataset.batch(N)\n",
    "  \n",
    "  # In eager mode, iterate in the Datset directly.\n",
    "  for images, labels in dataset:\n",
    "    numpy_images = images.numpy()\n",
    "    numpy_labels = labels.numpy()\n",
    "    break;\n",
    "\n",
    "  return numpy_images, numpy_labels\n",
    "\n",
    "some_flowers, some_labels = dataset_to_numpy_util(load_dataset(validation_filenames), 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load('gs://vtx-models/flower_photos/tpu/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m permutation \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mpermutation(\u001b[39m160\u001b[39m)\n\u001b[1;32m      3\u001b[0m some_flowers, some_labels \u001b[39m=\u001b[39m (some_flowers[permutation], some_labels[permutation])\n\u001b[0;32m----> 5\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(some_flowers, batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_UserObject' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# randomize the input so that you can execute multiple times to change results\n",
    "permutation = np.random.permutation(160)\n",
    "some_flowers, some_labels = (some_flowers[permutation], some_labels[permutation])\n",
    "\n",
    "predictions = model.predict(some_flowers, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
